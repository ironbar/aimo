{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune model with DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if using DPO can create a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    ")\n",
    "\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "from datasets import Dataset\n",
    "\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20819df32de4af19a0d67e3fa0ec67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = '/home/gbarbadillo/data/deepseekmath'\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "config.gradient_checkpointing = True\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map='auto',\n",
    "    torch_dtype=\"auto\", #torch.bfloat16 does not show speed differences\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=None,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# TODO: check pad token on prompt recovery notebook\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "      <th>problem_idx</th>\n",
       "      <th>max_prompt_length</th>\n",
       "      <th>chosen_length</th>\n",
       "      <th>rejected_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User: John computes the sum of the elements of...</td>\n",
       "      <td>from sympy import *\\n\\ndef sum_of_subset_sums(...</td>\n",
       "      <td>from itertools import combinations\\n\\ndef sum_...</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>166</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are an expert mathematical programmer. Sol...</td>\n",
       "      <td>from itertools import combinations\\n\\ndef sum_...</td>\n",
       "      <td>from sympy import binomial\\n\\ndef sum_of_subse...</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>168</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nUser: John computes the sum of the elements ...</td>\n",
       "      <td>from itertools import combinations\\n\\ndef sum_...</td>\n",
       "      <td>from sympy import binomial, Rational, simplify...</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>118</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User: John computes the sum of the elements of...</td>\n",
       "      <td>from itertools import combinations\\n\\ndef sum_...</td>\n",
       "      <td>from sympy import binomial, summation, symbols...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>179</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below is a math problem you are to solve (non ...</td>\n",
       "      <td>from itertools import combinations\\n\\ndef sum_...</td>\n",
       "      <td>from itertools import combinations\\n\\ndef sum_...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>163</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  User: John computes the sum of the elements of...   \n",
       "1  You are an expert mathematical programmer. Sol...   \n",
       "2  \\nUser: John computes the sum of the elements ...   \n",
       "3  User: John computes the sum of the elements of...   \n",
       "4  Below is a math problem you are to solve (non ...   \n",
       "\n",
       "                                              chosen  \\\n",
       "0  from sympy import *\\n\\ndef sum_of_subset_sums(...   \n",
       "1  from itertools import combinations\\n\\ndef sum_...   \n",
       "2  from itertools import combinations\\n\\ndef sum_...   \n",
       "3  from itertools import combinations\\n\\ndef sum_...   \n",
       "4  from itertools import combinations\\n\\ndef sum_...   \n",
       "\n",
       "                                            rejected  problem_idx  \\\n",
       "0  from itertools import combinations\\n\\ndef sum_...            0   \n",
       "1  from sympy import binomial\\n\\ndef sum_of_subse...            0   \n",
       "2  from sympy import binomial, Rational, simplify...            0   \n",
       "3  from sympy import binomial, summation, symbols...            0   \n",
       "4  from itertools import combinations\\n\\ndef sum_...            0   \n",
       "\n",
       "   max_prompt_length  chosen_length  rejected_length  \n",
       "0                 92            166              159  \n",
       "1                147            168              199  \n",
       "2                156            118              405  \n",
       "3                 99            179              459  \n",
       "4                100            163              189  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/hdd0/Kaggle/aimo/external_data/dpo/v1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_problem_ids = df['problem_idx'].unique()\n",
    "len(unique_problem_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10217 444\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "train_problem_ids = np.random.choice(unique_problem_ids, int(0.95 * len(unique_problem_ids)), replace=False)\n",
    "train_df = df[df['problem_idx'].isin(train_problem_ids)]\n",
    "test_df = df[~df['problem_idx'].isin(train_problem_ids)]\n",
    "assert len(train_df) + len(test_df) == len(df)\n",
    "assert set(train_df['problem_idx'].unique()).intersection(set(test_df['problem_idx'].unique())) == set()\n",
    "print(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the train dataset\n",
    "train_dataset = Dataset.from_pandas(train_df[['prompt', 'chosen', 'rejected']].sample(frac=1))\n",
    "eval_dataset = Dataset.from_pandas(test_df[['prompt', 'chosen', 'rejected']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# LoRA config based on https://github.com/ironbar/prompt_recovery/blob/main/notebooks/014_fine-tune_mistral_v2.ipynb\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.05, # 0.1, althought Vaca suggested to use 0.05 for big models\n",
    "        # r: the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters\n",
    "        r=16,\n",
    "        bias=\"none\",\n",
    "        # target_modules: The modules (for example, attention blocks) to apply the LoRA update matrices.\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.philschmid.de/dpo-align-llms-in-2024-with-trl\n",
    "# https://huggingface.co/docs/trl/main/en/dpo_trainer\n",
    "args = DPOConfig(\n",
    "    output_dir=\"/mnt/hdd0/Kaggle/aimo/experiments/18_dpo/01_dpo-first-steps\",               # directory to save and repository id\n",
    "    num_train_epochs=1,                     # number of training epochs\n",
    "    per_device_train_batch_size=2,         # batch size per device during training\n",
    "    gradient_accumulation_steps=8,          # number of steps before performing a backward/update pass\n",
    "    per_device_eval_batch_size=4,           # batch size for evaluation\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    learning_rate=2e-5,                     # 10x higher LR than QLoRA paper\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.1,                       # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"cosine\",             # use cosine learning rate scheduler\n",
    "    logging_steps=10,\n",
    "    save_steps=100,                         # when to save checkpoint\n",
    "    # save_total_limit=2,                     # limit the total amount of checkpoints\n",
    "    eval_strategy=\"steps\",                  # evaluate every n steps\n",
    "    eval_steps=100,                         # when to evaluate\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "    tf32=True,                              # use tf32 precision\n",
    "    push_to_hub=False,                      # push model to hub\n",
    "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
    "    model_init_kwargs=None,\n",
    "    max_length=1024,\n",
    "    max_prompt_length=300,\n",
    "    beta=0.1,                               # same as huggingface documentation, default value\n",
    "    loss_type=\"sigmoid\",                    # default value in huggingface documentation\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None, # set to none since we use peft\n",
    "    peft_config=peft_config,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# LoRA config based on https://github.com/ironbar/prompt_recovery/blob/main/notebooks/014_fine-tune_mistral_v2.ipynb\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.05, # 0.1, althought Vaca suggested to use 0.05 for big models\n",
    "        # r: the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters\n",
    "        r=16,\n",
    "        bias=\"none\",\n",
    "        # target_modules: The modules (for example, attention blocks) to apply the LoRA update matrices.\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.philschmid.de/dpo-align-llms-in-2024-with-trl\n",
    "# https://huggingface.co/docs/trl/main/en/dpo_trainer\n",
    "args = DPOConfig(\n",
    "    output_dir=\"/mnt/hdd0/Kaggle/aimo/experiments/18_dpo/02_shuffle_train_set\",               # directory to save and repository id\n",
    "    num_train_epochs=1,                     # number of training epochs\n",
    "    per_device_train_batch_size=2,         # batch size per device during training\n",
    "    gradient_accumulation_steps=8,          # number of steps before performing a backward/update pass\n",
    "    per_device_eval_batch_size=4,           # batch size for evaluation\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    learning_rate=2e-5,                     # 10x higher LR than QLoRA paper\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.1,                       # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"cosine\",             # use cosine learning rate scheduler\n",
    "    logging_steps=10,\n",
    "    save_steps=100,                         # when to save checkpoint\n",
    "    # save_total_limit=2,                     # limit the total amount of checkpoints\n",
    "    eval_strategy=\"steps\",                  # evaluate every n steps\n",
    "    eval_steps=100,                         # when to evaluate\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "    tf32=True,                              # use tf32 precision\n",
    "    push_to_hub=False,                      # push model to hub\n",
    "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
    "    model_init_kwargs=None,\n",
    "    max_length=1024,\n",
    "    max_prompt_length=300,\n",
    "    beta=0.1,                               # same as huggingface documentation, default value\n",
    "    loss_type=\"sigmoid\",                    # default value in huggingface documentation\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None, # set to none since we use peft\n",
    "    peft_config=peft_config,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove tf32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it train faster? No, but memory consumption is half. Thus I can train on a single GPU or double the batch size.\n",
    "\n",
    "If I train on a single gpu the training is faster, each iteration takes 18-20 seconds instead of 26. This happens because it avoids the comunication between gpus and the gpu is all the time working.\n",
    "\n",
    "I have tried using data parallelism but does not work.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "model = torch.nn.DataParallel(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config based on https://github.com/ironbar/prompt_recovery/blob/main/notebooks/014_fine-tune_mistral_v2.ipynb\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.05, # 0.1, althought Vaca suggested to use 0.05 for big models\n",
    "        # r: the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters\n",
    "        r=16,\n",
    "        bias=\"none\",\n",
    "        # target_modules: The modules (for example, attention blocks) to apply the LoRA update matrices.\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# https://www.philschmid.de/dpo-align-llms-in-2024-with-trl\n",
    "# https://huggingface.co/docs/trl/main/en/dpo_trainer\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments\n",
    "args = DPOConfig(\n",
    "    output_dir=\"/mnt/hdd0/Kaggle/aimo/experiments/18_dpo/03_4_epochs\",               # directory to save and repository id\n",
    "    num_train_epochs=4,                     # number of training epochs\n",
    "    per_device_train_batch_size=2,         # batch size per device during training\n",
    "    gradient_accumulation_steps=8,          # number of steps before performing a backward/update pass\n",
    "    per_device_eval_batch_size=2,           # batch size for evaluation\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    learning_rate=2e-5,                     # 10x higher LR than QLoRA paper\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.1,                       # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"cosine\",             # use cosine learning rate scheduler\n",
    "    logging_steps=10,\n",
    "    save_steps=100,                         # when to save checkpoint\n",
    "    # save_total_limit=2,                     # limit the total amount of checkpoints\n",
    "    eval_strategy=\"steps\",                  # evaluate every n steps\n",
    "    eval_steps=100,                         # when to evaluate\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "    # tf32=True,                              # use tf32 precision\n",
    "    push_to_hub=False,                      # push model to hub\n",
    "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
    "    model_init_kwargs=None,\n",
    "    max_length=1024,\n",
    "    max_prompt_length=300,\n",
    "    beta=0.1,                               # same as huggingface documentation, default value\n",
    "    loss_type=\"sigmoid\",                    # default value in huggingface documentation\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None, # set to none since we use peft\n",
    "    peft_config=peft_config,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use V1 dataset that has python block on prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:411: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1358084d3f014d3e8f48b1a79f9facb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10217 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b5d70487a04f9da977a8cec6d83d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f0f2663fc746f9a2b2e52a3b1cbb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6953, 'grad_norm': 3.421875, 'learning_rate': 4.000000000000001e-06, 'rewards/chosen': -0.0010355999693274498, 'rewards/rejected': 0.0015163278440013528, 'rewards/accuracies': 0.3812499940395355, 'rewards/margins': -0.002551927464082837, 'logps/rejected': -89.96470642089844, 'logps/chosen': -73.45173645019531, 'logits/rejected': 12.976682662963867, 'logits/chosen': 11.250761032104492, 'epoch': 0.02}\n",
      "{'loss': 0.6911, 'grad_norm': 3.484375, 'learning_rate': 8.000000000000001e-06, 'rewards/chosen': 0.004204194992780685, 'rewards/rejected': -0.0026238346472382545, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.00682802964001894, 'logps/rejected': -93.73872375488281, 'logps/chosen': -75.77989959716797, 'logits/rejected': 12.580449104309082, 'logits/chosen': 11.264778137207031, 'epoch': 0.03}\n",
      "{'loss': 0.6933, 'grad_norm': 3.8125, 'learning_rate': 1.2e-05, 'rewards/chosen': -0.007909061387181282, 'rewards/rejected': -0.010043960995972157, 'rewards/accuracies': 0.4937500059604645, 'rewards/margins': 0.0021349007729440928, 'logps/rejected': -85.61955261230469, 'logps/chosen': -71.77473449707031, 'logits/rejected': 12.91808795928955, 'logits/chosen': 11.758241653442383, 'epoch': 0.05}\n",
      "{'loss': 0.6961, 'grad_norm': 3.75, 'learning_rate': 1.6000000000000003e-05, 'rewards/chosen': -0.011660266667604446, 'rewards/rejected': -0.008814757689833641, 'rewards/accuracies': 0.5, 'rewards/margins': -0.002845508512109518, 'logps/rejected': -85.3555679321289, 'logps/chosen': -72.7454605102539, 'logits/rejected': 12.35066032409668, 'logits/chosen': 11.138945579528809, 'epoch': 0.06}\n",
      "{'loss': 0.671, 'grad_norm': 3.625, 'learning_rate': 2e-05, 'rewards/chosen': -0.024491067975759506, 'rewards/rejected': -0.07329987734556198, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.04880881309509277, 'logps/rejected': -89.63279724121094, 'logps/chosen': -73.16547393798828, 'logits/rejected': 12.280838012695312, 'logits/chosen': 11.111353874206543, 'epoch': 0.08}\n",
      "{'loss': 0.6659, 'grad_norm': 3.890625, 'learning_rate': 1.9999211703799988e-05, 'rewards/chosen': -0.10877909511327744, 'rewards/rejected': -0.17744314670562744, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.0686640590429306, 'logps/rejected': -93.5709228515625, 'logps/chosen': -73.9276351928711, 'logits/rejected': 12.51319694519043, 'logits/chosen': 10.777238845825195, 'epoch': 0.09}\n",
      "{'loss': 0.6588, 'grad_norm': 3.984375, 'learning_rate': 1.9996846939482125e-05, 'rewards/chosen': -0.17265889048576355, 'rewards/rejected': -0.2697221338748932, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.09706326574087143, 'logps/rejected': -89.55386352539062, 'logps/chosen': -79.27345275878906, 'logits/rejected': 11.630024909973145, 'logits/chosen': 10.76416015625, 'epoch': 0.11}\n",
      "{'loss': 0.62, 'grad_norm': 3.78125, 'learning_rate': 1.9992906079873363e-05, 'rewards/chosen': -0.018226301297545433, 'rewards/rejected': -0.21694691479206085, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.19872060418128967, 'logps/rejected': -96.2695541381836, 'logps/chosen': -72.03237915039062, 'logits/rejected': 11.943602561950684, 'logits/chosen': 9.877676010131836, 'epoch': 0.13}\n",
      "{'loss': 0.6211, 'grad_norm': 4.09375, 'learning_rate': 1.998738974628663e-05, 'rewards/chosen': 0.10189763456583023, 'rewards/rejected': -0.09961804002523422, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.20151567459106445, 'logps/rejected': -90.15303802490234, 'logps/chosen': -74.32209777832031, 'logits/rejected': 12.647866249084473, 'logits/chosen': 11.393961906433105, 'epoch': 0.14}\n",
      "{'loss': 0.5667, 'grad_norm': 3.78125, 'learning_rate': 1.9980298808422885e-05, 'rewards/chosen': 0.27374953031539917, 'rewards/rejected': -0.06662096828222275, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.3403705060482025, 'logps/rejected': -88.2237548828125, 'logps/chosen': -69.10552215576172, 'logits/rejected': 12.743274688720703, 'logits/chosen': 10.977850914001465, 'epoch': 0.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36bf0f027334d1c9be417ad2142fa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6154296398162842, 'eval_runtime': 241.8181, 'eval_samples_per_second': 1.836, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': 0.21208280324935913, 'eval_rewards/rejected': -0.014565981924533844, 'eval_rewards/accuracies': 0.7094594836235046, 'eval_rewards/margins': 0.22664877772331238, 'eval_logps/rejected': -90.63356018066406, 'eval_logps/chosen': -71.53353118896484, 'eval_logits/rejected': 12.089920043945312, 'eval_logits/chosen': 10.496620178222656, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5609, 'grad_norm': 3.640625, 'learning_rate': 1.9971634384234003e-05, 'rewards/chosen': 0.35068756341934204, 'rewards/rejected': -0.047439176589250565, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.3981267511844635, 'logps/rejected': -91.0195541381836, 'logps/chosen': -68.90591430664062, 'logits/rejected': 11.695329666137695, 'logits/chosen': 10.039606094360352, 'epoch': 0.17}\n",
      "{'loss': 0.5268, 'grad_norm': 4.75, 'learning_rate': 1.996139783974652e-05, 'rewards/chosen': 0.4217213988304138, 'rewards/rejected': -0.1326034516096115, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.5543248057365417, 'logps/rejected': -88.86412048339844, 'logps/chosen': -67.71923065185547, 'logits/rejected': 10.790011405944824, 'logits/chosen': 9.240800857543945, 'epoch': 0.19}\n",
      "{'loss': 0.4844, 'grad_norm': 3.6875, 'learning_rate': 1.9949590788846255e-05, 'rewards/chosen': 0.46751540899276733, 'rewards/rejected': -0.25762778520584106, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.7251432538032532, 'logps/rejected': -94.72216033935547, 'logps/chosen': -68.1296157836914, 'logits/rejected': 11.547857284545898, 'logits/chosen': 9.56755542755127, 'epoch': 0.2}\n",
      "{'loss': 0.5143, 'grad_norm': 6.71875, 'learning_rate': 1.9936215093023884e-05, 'rewards/chosen': 0.41882047057151794, 'rewards/rejected': -0.310648649930954, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.7294691205024719, 'logps/rejected': -89.09049987792969, 'logps/chosen': -73.92408752441406, 'logits/rejected': 11.303442001342773, 'logits/chosen': 10.138246536254883, 'epoch': 0.22}\n",
      "{'loss': 0.4744, 'grad_norm': 4.21875, 'learning_rate': 1.9921272861081445e-05, 'rewards/chosen': 0.5403920412063599, 'rewards/rejected': -0.32103461027145386, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.8614266514778137, 'logps/rejected': -88.01525115966797, 'logps/chosen': -64.86261749267578, 'logits/rejected': 10.979645729064941, 'logits/chosen': 9.367448806762695, 'epoch': 0.23}\n",
      "{'loss': 0.4461, 'grad_norm': 4.125, 'learning_rate': 1.9904766448799865e-05, 'rewards/chosen': 0.4606081545352936, 'rewards/rejected': -0.4045048654079437, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 0.8651129603385925, 'logps/rejected': -88.99159240722656, 'logps/chosen': -65.36336517333984, 'logits/rejected': 10.839167594909668, 'logits/chosen': 9.584976196289062, 'epoch': 0.25}\n",
      "{'loss': 0.4451, 'grad_norm': 5.34375, 'learning_rate': 1.9886698458567563e-05, 'rewards/chosen': 0.4927756190299988, 'rewards/rejected': -0.5470393896102905, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.0398149490356445, 'logps/rejected': -89.68167114257812, 'logps/chosen': -64.21214294433594, 'logits/rejected': 9.984037399291992, 'logits/chosen': 8.420381546020508, 'epoch': 0.27}\n",
      "{'loss': 0.4093, 'grad_norm': 3.8125, 'learning_rate': 1.986707173897015e-05, 'rewards/chosen': 0.35178104043006897, 'rewards/rejected': -0.9333891868591309, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.2851701974868774, 'logps/rejected': -100.39933013916016, 'logps/chosen': -71.72257995605469, 'logits/rejected': 10.558079719543457, 'logits/chosen': 9.02830982208252, 'epoch': 0.28}\n",
      "{'loss': 0.3692, 'grad_norm': 5.03125, 'learning_rate': 1.9845889384341317e-05, 'rewards/chosen': 0.43801411986351013, 'rewards/rejected': -0.936148464679718, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3741625547409058, 'logps/rejected': -98.3929672241211, 'logps/chosen': -67.43401336669922, 'logits/rejected': 10.945083618164062, 'logits/chosen': 9.258466720581055, 'epoch': 0.3}\n",
      "{'loss': 0.44, 'grad_norm': 4.0, 'learning_rate': 1.9823154734274997e-05, 'rewards/chosen': 0.2404804676771164, 'rewards/rejected': -1.1991206407546997, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.439601182937622, 'logps/rejected': -97.86885833740234, 'logps/chosen': -67.59368133544922, 'logits/rejected': 9.79316234588623, 'logits/chosen': 8.090784072875977, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ff3235e90a418096f04b40dc96ceb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5255338549613953, 'eval_runtime': 241.9775, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.917, 'eval_rewards/chosen': -0.19891761243343353, 'eval_rewards/rejected': -1.0811268091201782, 'eval_rewards/accuracies': 0.7252252101898193, 'eval_rewards/margins': 0.8822092413902283, 'eval_logps/rejected': -101.29917907714844, 'eval_logps/chosen': -75.64353942871094, 'eval_logits/rejected': 10.240870475769043, 'eval_logits/chosen': 8.471366882324219, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.358, 'grad_norm': 5.09375, 'learning_rate': 1.9798871373098845e-05, 'rewards/chosen': 0.261913925409317, 'rewards/rejected': -1.1730979681015015, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.435011863708496, 'logps/rejected': -98.83033752441406, 'logps/chosen': -67.28208923339844, 'logits/rejected': 9.855779647827148, 'logits/chosen': 7.917764186859131, 'epoch': 0.33}\n",
      "{'loss': 0.3286, 'grad_norm': 4.59375, 'learning_rate': 1.9773043129309123e-05, 'rewards/chosen': 0.1862579882144928, 'rewards/rejected': -1.662421464920044, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 1.8486793041229248, 'logps/rejected': -110.51202392578125, 'logps/chosen': -69.61744689941406, 'logits/rejected': 10.02865982055664, 'logits/chosen': 8.087186813354492, 'epoch': 0.34}\n",
      "{'loss': 0.3816, 'grad_norm': 5.71875, 'learning_rate': 1.974567407496712e-05, 'rewards/chosen': 0.012288955971598625, 'rewards/rejected': -1.5592478513717651, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.571536898612976, 'logps/rejected': -98.54856872558594, 'logps/chosen': -69.28533172607422, 'logits/rejected': 9.364886283874512, 'logits/chosen': 7.830629825592041, 'epoch': 0.36}\n",
      "{'loss': 0.3715, 'grad_norm': 5.8125, 'learning_rate': 1.9716768525057147e-05, 'rewards/chosen': 0.028798777610063553, 'rewards/rejected': -1.678203821182251, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.7070026397705078, 'logps/rejected': -103.46992492675781, 'logps/chosen': -71.5570297241211, 'logits/rejected': 9.485664367675781, 'logits/chosen': 8.06270694732666, 'epoch': 0.38}\n",
      "{'loss': 0.2751, 'grad_norm': 5.25, 'learning_rate': 1.968633103680623e-05, 'rewards/chosen': 0.21375040709972382, 'rewards/rejected': -2.128283739089966, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.342034101486206, 'logps/rejected': -113.3722915649414, 'logps/chosen': -68.04328918457031, 'logits/rejected': 9.280930519104004, 'logits/chosen': 6.364667892456055, 'epoch': 0.39}\n",
      "{'loss': 0.3663, 'grad_norm': 4.53125, 'learning_rate': 1.9654366408965637e-05, 'rewards/chosen': 0.004364615771919489, 'rewards/rejected': -1.7454134225845337, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.7497780323028564, 'logps/rejected': -107.91746520996094, 'logps/chosen': -73.63036346435547, 'logits/rejected': 9.961641311645508, 'logits/chosen': 8.41571044921875, 'epoch': 0.41}\n",
      "{'loss': 0.4127, 'grad_norm': 8.9375, 'learning_rate': 1.9620879681054293e-05, 'rewards/chosen': 0.4034096598625183, 'rewards/rejected': -1.408563256263733, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.8119728565216064, 'logps/rejected': -95.85096740722656, 'logps/chosen': -68.8715591430664, 'logits/rejected': 8.509012222290039, 'logits/chosen': 7.146143913269043, 'epoch': 0.42}\n",
      "{'loss': 0.2189, 'grad_norm': 3.921875, 'learning_rate': 1.9585876132564277e-05, 'rewards/chosen': 0.5328810214996338, 'rewards/rejected': -1.6532535552978516, 'rewards/accuracies': 0.9375, 'rewards/margins': 2.1861345767974854, 'logps/rejected': -106.38575744628906, 'logps/chosen': -69.74967193603516, 'logits/rejected': 9.387953758239746, 'logits/chosen': 8.026236534118652, 'epoch': 0.44}\n",
      "{'loss': 0.2424, 'grad_norm': 6.5625, 'learning_rate': 1.9549361282128446e-05, 'rewards/chosen': 0.3637941777706146, 'rewards/rejected': -1.7217657566070557, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 2.085559606552124, 'logps/rejected': -106.0354232788086, 'logps/chosen': -69.7972412109375, 'logits/rejected': 8.765376091003418, 'logits/chosen': 7.228218078613281, 'epoch': 0.45}\n",
      "{'loss': 0.2625, 'grad_norm': 6.21875, 'learning_rate': 1.9511340886650362e-05, 'rewards/chosen': 0.30868586897850037, 'rewards/rejected': -2.0550057888031006, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 2.363691806793213, 'logps/rejected': -106.6400375366211, 'logps/chosen': -70.68836975097656, 'logits/rejected': 8.191943168640137, 'logits/chosen': 6.492283821105957, 'epoch': 0.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c705d7ed2a8041378935b5f80b62d69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5561589002609253, 'eval_runtime': 241.8968, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -0.7597678303718567, 'eval_rewards/rejected': -1.8409866094589233, 'eval_rewards/accuracies': 0.7207207083702087, 'eval_rewards/margins': 1.0812187194824219, 'eval_logps/rejected': -108.89778900146484, 'eval_logps/chosen': -81.25204467773438, 'eval_logits/rejected': 8.22982120513916, 'eval_logits/chosen': 6.488012790679932, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2253, 'grad_norm': 7.4375, 'learning_rate': 1.947182094039668e-05, 'rewards/chosen': 0.17852099239826202, 'rewards/rejected': -2.288707733154297, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 2.467228889465332, 'logps/rejected': -105.67063903808594, 'logps/chosen': -70.11473083496094, 'logits/rejected': 7.758152008056641, 'logits/chosen': 6.562679290771484, 'epoch': 0.49}\n",
      "{'loss': 0.2148, 'grad_norm': 4.875, 'learning_rate': 1.9430807674052092e-05, 'rewards/chosen': 0.2110137939453125, 'rewards/rejected': -2.6799962520599365, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 2.891010046005249, 'logps/rejected': -115.49813079833984, 'logps/chosen': -67.47633361816406, 'logits/rejected': 7.4566850662231445, 'logits/chosen': 5.550971984863281, 'epoch': 0.5}\n",
      "{'loss': 0.2884, 'grad_norm': 9.5625, 'learning_rate': 1.9388307553737006e-05, 'rewards/chosen': 0.004266184754669666, 'rewards/rejected': -2.7237489223480225, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 2.728015422821045, 'logps/rejected': -113.53993225097656, 'logps/chosen': -69.99850463867188, 'logits/rejected': 6.7307634353637695, 'logits/chosen': 4.867996692657471, 'epoch': 0.52}\n",
      "{'loss': 0.3197, 'grad_norm': 7.71875, 'learning_rate': 1.934432727998808e-05, 'rewards/chosen': -0.24104365706443787, 'rewards/rejected': -2.552061080932617, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.3110175132751465, 'logps/rejected': -112.2347640991211, 'logps/chosen': -74.38872528076172, 'logits/rejected': 7.206686496734619, 'logits/chosen': 5.548805236816406, 'epoch': 0.53}\n",
      "{'loss': 0.2191, 'grad_norm': 6.125, 'learning_rate': 1.929887378670186e-05, 'rewards/chosen': -0.08226705342531204, 'rewards/rejected': -2.7970001697540283, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 2.714733123779297, 'logps/rejected': -114.03065490722656, 'logps/chosen': -71.74553680419922, 'logits/rejected': 6.871546268463135, 'logits/chosen': 5.171416759490967, 'epoch': 0.55}\n",
      "{'loss': 0.2593, 'grad_norm': 9.375, 'learning_rate': 1.9251954240041543e-05, 'rewards/chosen': 0.03597455471754074, 'rewards/rejected': -2.591658353805542, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 2.6276330947875977, 'logps/rejected': -110.72224426269531, 'logps/chosen': -71.1788330078125, 'logits/rejected': 6.166470050811768, 'logits/chosen': 4.745514392852783, 'epoch': 0.56}\n",
      "{'loss': 0.3126, 'grad_norm': 7.15625, 'learning_rate': 1.9203576037307205e-05, 'rewards/chosen': -0.13404580950737, 'rewards/rejected': -2.7757747173309326, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 2.6417288780212402, 'logps/rejected': -115.1766357421875, 'logps/chosen': -75.42822265625, 'logits/rejected': 6.7346625328063965, 'logits/chosen': 4.905999183654785, 'epoch': 0.58}\n",
      "{'loss': 0.1674, 'grad_norm': 5.96875, 'learning_rate': 1.9153746805769512e-05, 'rewards/chosen': 0.3914136290550232, 'rewards/rejected': -3.00498628616333, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 3.396399736404419, 'logps/rejected': -123.84989166259766, 'logps/chosen': -65.85682678222656, 'logits/rejected': 6.550193786621094, 'logits/chosen': 4.335546970367432, 'epoch': 0.6}\n",
      "{'loss': 0.2439, 'grad_norm': 8.1875, 'learning_rate': 1.9102474401467248e-05, 'rewards/chosen': 0.4281335473060608, 'rewards/rejected': -2.73821759223938, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 3.166351079940796, 'logps/rejected': -113.40633392333984, 'logps/chosen': -66.8058090209961, 'logits/rejected': 5.3904619216918945, 'logits/chosen': 4.22568941116333, 'epoch': 0.61}\n",
      "{'loss': 0.2021, 'grad_norm': 8.25, 'learning_rate': 1.9049766907968706e-05, 'rewards/chosen': 0.42990994453430176, 'rewards/rejected': -2.948756694793701, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 3.378666639328003, 'logps/rejected': -116.96595764160156, 'logps/chosen': -66.22726440429688, 'logits/rejected': 6.152690410614014, 'logits/chosen': 4.505735874176025, 'epoch': 0.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bcb9a3362d4956901a2e9864bf0900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6126380562782288, 'eval_runtime': 242.0941, 'eval_samples_per_second': 1.834, 'eval_steps_per_second': 0.917, 'eval_rewards/chosen': -1.1078107357025146, 'eval_rewards/rejected': -2.3548102378845215, 'eval_rewards/accuracies': 0.7184684872627258, 'eval_rewards/margins': 1.2469996213912964, 'eval_logps/rejected': -114.0360107421875, 'eval_logps/chosen': -84.73246765136719, 'eval_logits/rejected': 6.159877300262451, 'eval_logits/chosen': 4.411309242248535, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2899, 'grad_norm': 11.25, 'learning_rate': 1.899563263509725e-05, 'rewards/chosen': 0.04579009860754013, 'rewards/rejected': -2.864750385284424, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.9105403423309326, 'logps/rejected': -124.10768127441406, 'logps/chosen': -72.30010223388672, 'logits/rejected': 5.737375736236572, 'logits/chosen': 3.709618330001831, 'epoch': 0.64}\n",
      "{'loss': 0.2374, 'grad_norm': 6.03125, 'learning_rate': 1.89400801176212e-05, 'rewards/chosen': 0.2087489366531372, 'rewards/rejected': -2.9790165424346924, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.187765598297119, 'logps/rejected': -115.80079650878906, 'logps/chosen': -70.25961303710938, 'logits/rejected': 6.558821201324463, 'logits/chosen': 4.50593376159668, 'epoch': 0.66}\n",
      "{'loss': 0.1514, 'grad_norm': 8.5625, 'learning_rate': 1.8883118113908243e-05, 'rewards/chosen': 0.24212777614593506, 'rewards/rejected': -3.027545928955078, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 3.2696738243103027, 'logps/rejected': -116.52486419677734, 'logps/chosen': -71.80606842041016, 'logits/rejected': 6.397181987762451, 'logits/chosen': 4.967236042022705, 'epoch': 0.67}\n",
      "{'loss': 0.1896, 'grad_norm': 3.40625, 'learning_rate': 1.8824755604544592e-05, 'rewards/chosen': 0.10589425265789032, 'rewards/rejected': -3.064171314239502, 'rewards/accuracies': 0.9375, 'rewards/margins': 3.1700656414031982, 'logps/rejected': -120.2813720703125, 'logps/chosen': -69.83303833007812, 'logits/rejected': 6.464875221252441, 'logits/chosen': 4.678574562072754, 'epoch': 0.69}\n",
      "{'loss': 0.1636, 'grad_norm': 2.734375, 'learning_rate': 1.8765001790919122e-05, 'rewards/chosen': -0.0008802115917205811, 'rewards/rejected': -3.3301873207092285, 'rewards/accuracies': 0.9375, 'rewards/margins': 3.3293068408966064, 'logps/rejected': -122.52326965332031, 'logps/chosen': -70.97379302978516, 'logits/rejected': 6.586985111236572, 'logits/chosen': 5.059308052062988, 'epoch': 0.7}\n",
      "{'loss': 0.1875, 'grad_norm': 8.9375, 'learning_rate': 1.8703866093772672e-05, 'rewards/chosen': -0.23919577896595, 'rewards/rejected': -3.6408913135528564, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.4016952514648438, 'logps/rejected': -125.68034362792969, 'logps/chosen': -77.51303100585938, 'logits/rejected': 6.272877216339111, 'logits/chosen': 4.781623363494873, 'epoch': 0.72}\n",
      "{'loss': 0.2077, 'grad_norm': 11.8125, 'learning_rate': 1.8641358151712792e-05, 'rewards/chosen': -0.2539520263671875, 'rewards/rejected': -3.7470474243164062, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.493095874786377, 'logps/rejected': -123.8921127319336, 'logps/chosen': -74.56578063964844, 'logits/rejected': 6.174221515655518, 'logits/chosen': 4.780288219451904, 'epoch': 0.74}\n",
      "{'loss': 0.2224, 'grad_norm': 5.6875, 'learning_rate': 1.857748781969412e-05, 'rewards/chosen': -0.26814815402030945, 'rewards/rejected': -4.004043102264404, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 3.7358951568603516, 'logps/rejected': -123.17387390136719, 'logps/chosen': -74.50941467285156, 'logits/rejected': 5.862265110015869, 'logits/chosen': 4.192135810852051, 'epoch': 0.75}\n",
      "{'loss': 0.1404, 'grad_norm': 6.125, 'learning_rate': 1.8512265167464665e-05, 'rewards/chosen': -0.19537082314491272, 'rewards/rejected': -4.1136860847473145, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 3.9183146953582764, 'logps/rejected': -138.82220458984375, 'logps/chosen': -71.7365951538086, 'logits/rejected': 5.22904109954834, 'logits/chosen': 3.3552584648132324, 'epoch': 0.77}\n",
      "{'loss': 0.2425, 'grad_norm': 6.8125, 'learning_rate': 1.8445700477978207e-05, 'rewards/chosen': -0.3961212933063507, 'rewards/rejected': -4.138488292694092, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 3.7423667907714844, 'logps/rejected': -123.38652038574219, 'logps/chosen': -78.7310562133789, 'logits/rejected': 6.319618225097656, 'logits/chosen': 4.601764678955078, 'epoch': 0.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1444fad37fd548fbbe6a14da86d0efc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6795856356620789, 'eval_runtime': 241.8934, 'eval_samples_per_second': 1.836, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -1.8795621395111084, 'eval_rewards/rejected': -3.12912917137146, 'eval_rewards/accuracies': 0.684684693813324, 'eval_rewards/margins': 1.2495671510696411, 'eval_logps/rejected': -121.77919006347656, 'eval_logps/chosen': -92.4499740600586, 'eval_logits/rejected': 6.320049285888672, 'eval_logits/chosen': 4.5810346603393555, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.182, 'grad_norm': 5.59375, 'learning_rate': 1.8377804245773094e-05, 'rewards/chosen': -0.39600902795791626, 'rewards/rejected': -4.173902988433838, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 3.7778942584991455, 'logps/rejected': -123.6973648071289, 'logps/chosen': -76.1230239868164, 'logits/rejected': 6.39043664932251, 'logits/chosen': 5.02389669418335, 'epoch': 0.8}\n",
      "{'loss': 0.0997, 'grad_norm': 4.65625, 'learning_rate': 1.8308587175317708e-05, 'rewards/chosen': -0.1254158914089203, 'rewards/rejected': -4.295899868011475, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 4.170483589172363, 'logps/rejected': -132.63800048828125, 'logps/chosen': -73.69773864746094, 'logits/rejected': 6.727433204650879, 'logits/chosen': 4.744823932647705, 'epoch': 0.81}\n",
      "{'loss': 0.0916, 'grad_norm': 7.71875, 'learning_rate': 1.823806017932276e-05, 'rewards/chosen': -0.08714324980974197, 'rewards/rejected': -4.550434589385986, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 4.463292121887207, 'logps/rejected': -130.517578125, 'logps/chosen': -70.69741821289062, 'logits/rejected': 6.3287553787231445, 'logits/chosen': 4.272960186004639, 'epoch': 0.83}\n",
      "{'loss': 0.1771, 'grad_norm': 1.1171875, 'learning_rate': 1.8166234377020845e-05, 'rewards/chosen': -0.5732592344284058, 'rewards/rejected': -4.945068359375, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 4.371809482574463, 'logps/rejected': -138.67190551757812, 'logps/chosen': -79.16020202636719, 'logits/rejected': 5.3096489906311035, 'logits/chosen': 3.584244966506958, 'epoch': 0.85}\n",
      "{'loss': 0.2617, 'grad_norm': 16.75, 'learning_rate': 1.8093121092413367e-05, 'rewards/chosen': -0.6568585634231567, 'rewards/rejected': -4.720745086669922, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.063885688781738, 'logps/rejected': -134.21060180664062, 'logps/chosen': -79.7665786743164, 'logits/rejected': 5.1724348068237305, 'logits/chosen': 3.698765993118286, 'epoch': 0.86}\n",
      "{'loss': 0.3044, 'grad_norm': 15.625, 'learning_rate': 1.8018731852485206e-05, 'rewards/chosen': -0.8988311886787415, 'rewards/rejected': -4.812489986419678, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.913658857345581, 'logps/rejected': -135.02743530273438, 'logps/chosen': -84.65816497802734, 'logits/rejected': 4.709410667419434, 'logits/chosen': 2.9307291507720947, 'epoch': 0.88}\n",
      "{'loss': 0.1929, 'grad_norm': 10.25, 'learning_rate': 1.7943078385387398e-05, 'rewards/chosen': -0.35890573263168335, 'rewards/rejected': -4.730302333831787, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 4.371397018432617, 'logps/rejected': -135.91006469726562, 'logps/chosen': -70.0702133178711, 'logits/rejected': 5.538408279418945, 'logits/chosen': 3.5441575050354004, 'epoch': 0.89}\n",
      "{'loss': 0.1452, 'grad_norm': 9.625, 'learning_rate': 1.786617261858807e-05, 'rewards/chosen': -0.27921491861343384, 'rewards/rejected': -4.8097662925720215, 'rewards/accuracies': 0.9375, 'rewards/margins': 4.530551433563232, 'logps/rejected': -134.5310516357422, 'logps/chosen': -74.68928527832031, 'logits/rejected': 4.986422538757324, 'logits/chosen': 3.6562600135803223, 'epoch': 0.91}\n",
      "{'loss': 0.1241, 'grad_norm': 7.21875, 'learning_rate': 1.778802667699196e-05, 'rewards/chosen': -0.18041206896305084, 'rewards/rejected': -4.564143180847168, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 4.383731365203857, 'logps/rejected': -137.1083221435547, 'logps/chosen': -75.59150695800781, 'logits/rejected': 4.978575229644775, 'logits/chosen': 3.235811710357666, 'epoch': 0.92}\n",
      "{'loss': 0.1141, 'grad_norm': 2.75, 'learning_rate': 1.770865288102884e-05, 'rewards/chosen': -0.13020597398281097, 'rewards/rejected': -4.610398769378662, 'rewards/accuracies': 0.96875, 'rewards/margins': 4.4801926612854, 'logps/rejected': -131.2198944091797, 'logps/chosen': -72.04034423828125, 'logits/rejected': 4.645544052124023, 'logits/chosen': 2.890097141265869, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c7c36a808142f79c179db99e007390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6472303867340088, 'eval_runtime': 241.958, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -2.109342098236084, 'eval_rewards/rejected': -3.6435024738311768, 'eval_rewards/accuracies': 0.7139639854431152, 'eval_rewards/margins': 1.5341600179672241, 'eval_logps/rejected': -126.92292785644531, 'eval_logps/chosen': -94.7477798461914, 'eval_logits/rejected': 5.0846452713012695, 'eval_logits/chosen': 3.3640599250793457, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1042, 'grad_norm': 11.5, 'learning_rate': 1.762806374471105e-05, 'rewards/chosen': -0.4803459048271179, 'rewards/rejected': -5.247006416320801, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 4.766659736633301, 'logps/rejected': -138.08908081054688, 'logps/chosen': -79.90936279296875, 'logits/rejected': 5.17446231842041, 'logits/chosen': 3.205935001373291, 'epoch': 0.96}\n",
      "{'loss': 0.1424, 'grad_norm': 2.546875, 'learning_rate': 1.7546271973660577e-05, 'rewards/chosen': -0.7516440153121948, 'rewards/rejected': -5.367527961730957, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 4.615883827209473, 'logps/rejected': -143.3642120361328, 'logps/chosen': -82.21552276611328, 'logits/rejected': 4.980582237243652, 'logits/chosen': 3.2851309776306152, 'epoch': 0.97}\n",
      "{'loss': 0.1092, 'grad_norm': 3.140625, 'learning_rate': 1.746329046310588e-05, 'rewards/chosen': -0.8194684982299805, 'rewards/rejected': -5.632216453552246, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 4.812747955322266, 'logps/rejected': -147.114501953125, 'logps/chosen': -79.86402893066406, 'logits/rejected': 5.1003007888793945, 'logits/chosen': 3.174739360809326, 'epoch': 0.99}\n",
      "{'loss': 0.1287, 'grad_norm': 3.78125, 'learning_rate': 1.7379132295848854e-05, 'rewards/chosen': -0.6734558939933777, 'rewards/rejected': -5.385013103485107, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 4.711556911468506, 'logps/rejected': -140.45535278320312, 'logps/chosen': -81.07623291015625, 'logits/rejected': 5.441338539123535, 'logits/chosen': 3.8192570209503174, 'epoch': 1.0}\n",
      "{'loss': 0.095, 'grad_norm': 1.2265625, 'learning_rate': 1.729381074020218e-05, 'rewards/chosen': -0.3989674150943756, 'rewards/rejected': -5.786466121673584, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 5.387498378753662, 'logps/rejected': -147.73580932617188, 'logps/chosen': -74.36170959472656, 'logits/rejected': 5.310675144195557, 'logits/chosen': 3.490328311920166, 'epoch': 1.02}\n",
      "{'loss': 0.0442, 'grad_norm': 1.1640625, 'learning_rate': 1.720733924789749e-05, 'rewards/chosen': -0.3257407546043396, 'rewards/rejected': -6.024110794067383, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 5.698370933532715, 'logps/rejected': -147.29251098632812, 'logps/chosen': -74.43800354003906, 'logits/rejected': 4.687777996063232, 'logits/chosen': 3.0486884117126465, 'epoch': 1.03}\n",
      "{'loss': 0.0514, 'grad_norm': 0.65625, 'learning_rate': 1.711973145196453e-05, 'rewards/chosen': -0.20026710629463196, 'rewards/rejected': -6.184993743896484, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 5.984726428985596, 'logps/rejected': -144.99716186523438, 'logps/chosen': -73.88050842285156, 'logits/rejected': 4.766570568084717, 'logits/chosen': 3.1552677154541016, 'epoch': 1.05}\n",
      "{'loss': 0.0366, 'grad_norm': 0.1552734375, 'learning_rate': 1.7031001164581828e-05, 'rewards/chosen': -0.5178815722465515, 'rewards/rejected': -6.775450229644775, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 6.257568359375, 'logps/rejected': -156.57589721679688, 'logps/chosen': -75.87669372558594, 'logits/rejected': 4.855984210968018, 'logits/chosen': 2.890007257461548, 'epoch': 1.06}\n",
      "{'loss': 0.0554, 'grad_norm': 15.875, 'learning_rate': 1.6941162374899062e-05, 'rewards/chosen': -0.8231027722358704, 'rewards/rejected': -7.075827121734619, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 6.252723693847656, 'logps/rejected': -157.43295288085938, 'logps/chosen': -81.2816390991211, 'logits/rejected': 3.66680908203125, 'logits/chosen': 1.7152189016342163, 'epoch': 1.08}\n",
      "{'loss': 0.0564, 'grad_norm': 1.6015625, 'learning_rate': 1.6850229246831533e-05, 'rewards/chosen': -0.6775291562080383, 'rewards/rejected': -7.25034236907959, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 6.572812557220459, 'logps/rejected': -162.2257537841797, 'logps/chosen': -78.28895568847656, 'logits/rejected': 2.4433443546295166, 'logits/chosen': 0.17213912308216095, 'epoch': 1.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca27d71e04442eaa2872bf402f691ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7407044172286987, 'eval_runtime': 241.9236, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -3.395005702972412, 'eval_rewards/rejected': -5.643986225128174, 'eval_rewards/accuracies': 0.7567567825317383, 'eval_rewards/margins': 2.2489802837371826, 'eval_logps/rejected': -146.92776489257812, 'eval_logps/chosen': -107.60442352294922, 'eval_logits/rejected': 1.5974797010421753, 'eval_logits/chosen': -0.047791413962841034, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0511, 'grad_norm': 1.9375, 'learning_rate': 1.6758216116827106e-05, 'rewards/chosen': -0.8284792900085449, 'rewards/rejected': -7.220571994781494, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 6.392092704772949, 'logps/rejected': -152.17739868164062, 'logps/chosen': -77.2468490600586, 'logits/rejected': 0.6463303565979004, 'logits/chosen': -0.9613253474235535, 'epoch': 1.11}\n",
      "{'loss': 0.0751, 'grad_norm': 2.09375, 'learning_rate': 1.6665137491605924e-05, 'rewards/chosen': -0.9346145391464233, 'rewards/rejected': -7.900615692138672, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 6.966001033782959, 'logps/rejected': -164.94879150390625, 'logps/chosen': -79.9521255493164, 'logits/rejected': 1.2978918552398682, 'logits/chosen': -0.7608845829963684, 'epoch': 1.13}\n",
      "{'loss': 0.1016, 'grad_norm': 1.453125, 'learning_rate': 1.6571008045873305e-05, 'rewards/chosen': -1.2113415002822876, 'rewards/rejected': -7.9060516357421875, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.694710731506348, 'logps/rejected': -165.17031860351562, 'logps/chosen': -89.03498840332031, 'logits/rejected': 1.317841649055481, 'logits/chosen': -0.3023698329925537, 'epoch': 1.14}\n",
      "{'loss': 0.0365, 'grad_norm': 7.65625, 'learning_rate': 1.647584262000612e-05, 'rewards/chosen': -0.732354462146759, 'rewards/rejected': -7.918454647064209, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 7.186100006103516, 'logps/rejected': -166.6265869140625, 'logps/chosen': -78.42164611816406, 'logits/rejected': 1.1979037523269653, 'logits/chosen': -0.7401527762413025, 'epoch': 1.16}\n",
      "{'loss': 0.0508, 'grad_norm': 2.21875, 'learning_rate': 1.6379656217713086e-05, 'rewards/chosen': -1.4439504146575928, 'rewards/rejected': -8.072981834411621, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 6.629031181335449, 'logps/rejected': -169.03414916992188, 'logps/chosen': -88.30335998535156, 'logits/rejected': 0.9340206980705261, 'logits/chosen': -0.8189012408256531, 'epoch': 1.17}\n",
      "{'loss': 0.0391, 'grad_norm': 1.84375, 'learning_rate': 1.628246400366929e-05, 'rewards/chosen': -1.4226629734039307, 'rewards/rejected': -8.65053939819336, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 7.227877140045166, 'logps/rejected': -176.22775268554688, 'logps/chosen': -88.13371276855469, 'logits/rejected': 1.0531575679779053, 'logits/chosen': -0.8667710423469543, 'epoch': 1.19}\n",
      "{'loss': 0.0602, 'grad_norm': 0.6875, 'learning_rate': 1.618428130112533e-05, 'rewards/chosen': -1.1623823642730713, 'rewards/rejected': -8.183852195739746, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 7.021470546722412, 'logps/rejected': -172.5473175048828, 'logps/chosen': -83.02055358886719, 'logits/rejected': 0.8434299230575562, 'logits/chosen': -0.7940423488616943, 'epoch': 1.21}\n",
      "{'loss': 0.0898, 'grad_norm': 1.453125, 'learning_rate': 1.6085123589491474e-05, 'rewards/chosen': -1.413297414779663, 'rewards/rejected': -8.405696868896484, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 6.9923996925354, 'logps/rejected': -171.8319549560547, 'logps/chosen': -85.96202087402344, 'logits/rejected': 0.191961869597435, 'logits/chosen': -1.87881338596344, 'epoch': 1.22}\n",
      "{'loss': 0.0854, 'grad_norm': 5.75, 'learning_rate': 1.5985006501897172e-05, 'rewards/chosen': -1.3789163827896118, 'rewards/rejected': -8.101319313049316, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 6.722403049468994, 'logps/rejected': -172.09176635742188, 'logps/chosen': -87.93663024902344, 'logits/rejected': -0.4628960192203522, 'logits/chosen': -2.185739755630493, 'epoch': 1.24}\n",
      "{'loss': 0.015, 'grad_norm': 0.451171875, 'learning_rate': 1.5883945822726373e-05, 'rewards/chosen': -0.9634860157966614, 'rewards/rejected': -8.846563339233398, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 7.883077144622803, 'logps/rejected': -182.56423950195312, 'logps/chosen': -79.97074890136719, 'logits/rejected': 1.1288797855377197, 'logits/chosen': -0.7714605927467346, 'epoch': 1.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e21745b6b14c7eb08d234cc98ddbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8031892776489258, 'eval_runtime': 241.5978, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 0.919, 'eval_rewards/chosen': -4.136497497558594, 'eval_rewards/rejected': -6.403458118438721, 'eval_rewards/accuracies': 0.727477490901947, 'eval_rewards/margins': 2.2669601440429688, 'eval_logps/rejected': -154.52249145507812, 'eval_logps/chosen': -115.01934051513672, 'eval_logits/rejected': 0.3165725767612457, 'eval_logits/chosen': -1.3544776439666748, 'epoch': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0438, 'grad_norm': 3.625, 'learning_rate': 1.5781957485128947e-05, 'rewards/chosen': -1.5442534685134888, 'rewards/rejected': -8.52992057800293, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 6.985666751861572, 'logps/rejected': -171.83563232421875, 'logps/chosen': -88.0844497680664, 'logits/rejected': 0.35517340898513794, 'logits/chosen': -1.5864067077636719, 'epoch': 1.27}\n",
      "{'loss': 0.0672, 'grad_norm': 9.125, 'learning_rate': 1.5679057568508683e-05, 'rewards/chosen': -1.5455121994018555, 'rewards/rejected': -8.769659042358398, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 7.224146842956543, 'logps/rejected': -173.4645233154297, 'logps/chosen': -91.39881896972656, 'logits/rejected': -1.1188387870788574, 'logits/chosen': -2.5360589027404785, 'epoch': 1.28}\n",
      "{'loss': 0.043, 'grad_norm': 2.328125, 'learning_rate': 1.557526229598824e-05, 'rewards/chosen': -1.1841191053390503, 'rewards/rejected': -8.379477500915527, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 7.1953582763671875, 'logps/rejected': -173.0520477294922, 'logps/chosen': -84.29417419433594, 'logits/rejected': -0.12457376718521118, 'logits/chosen': -2.1490588188171387, 'epoch': 1.3}\n",
      "{'loss': 0.0567, 'grad_norm': 0.212890625, 'learning_rate': 1.5470588031851394e-05, 'rewards/chosen': -1.1535627841949463, 'rewards/rejected': -8.35786247253418, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 7.204300880432129, 'logps/rejected': -174.0691375732422, 'logps/chosen': -85.67767333984375, 'logits/rejected': 1.172581434249878, 'logits/chosen': -0.6485610008239746, 'epoch': 1.32}\n",
      "{'loss': 0.0227, 'grad_norm': 2.53125, 'learning_rate': 1.536505127896308e-05, 'rewards/chosen': -1.1668815612792969, 'rewards/rejected': -8.98090934753418, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 7.814028739929199, 'logps/rejected': -180.8386993408203, 'logps/chosen': -85.8467025756836, 'logits/rejected': 0.9139190912246704, 'logits/chosen': -1.0229758024215698, 'epoch': 1.33}\n",
      "{'loss': 0.0199, 'grad_norm': 2.71875, 'learning_rate': 1.5258668676167548e-05, 'rewards/chosen': -1.305934190750122, 'rewards/rejected': -8.989471435546875, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 7.683536529541016, 'logps/rejected': -174.06939697265625, 'logps/chosen': -84.79783630371094, 'logits/rejected': 0.3114430010318756, 'logits/chosen': -1.6775872707366943, 'epoch': 1.35}\n",
      "{'loss': 0.0196, 'grad_norm': 0.388671875, 'learning_rate': 1.5151456995665105e-05, 'rewards/chosen': -0.9560238718986511, 'rewards/rejected': -9.024230003356934, 'rewards/accuracies': 1.0, 'rewards/margins': 8.068206787109375, 'logps/rejected': -176.6070098876953, 'logps/chosen': -79.16069793701172, 'logits/rejected': -0.9677642583847046, 'logits/chosen': -2.541410446166992, 'epoch': 1.36}\n",
      "{'loss': 0.0463, 'grad_norm': 1.78125, 'learning_rate': 1.5043433140367821e-05, 'rewards/chosen': -1.2286756038665771, 'rewards/rejected': -8.851816177368164, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 7.623141288757324, 'logps/rejected': -175.5323944091797, 'logps/chosen': -85.1431655883789, 'logits/rejected': -0.9005630612373352, 'logits/chosen': -2.5923056602478027, 'epoch': 1.38}\n",
      "{'loss': 0.0469, 'grad_norm': 1.1796875, 'learning_rate': 1.4934614141234618e-05, 'rewards/chosen': -1.165952444076538, 'rewards/rejected': -9.066886901855469, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 7.90093469619751, 'logps/rejected': -177.24166870117188, 'logps/chosen': -81.6363754272461, 'logits/rejected': -1.8803622722625732, 'logits/chosen': -3.430119276046753, 'epoch': 1.39}\n",
      "{'loss': 0.0755, 'grad_norm': 2.34375, 'learning_rate': 1.4825017154586206e-05, 'rewards/chosen': -1.831830620765686, 'rewards/rejected': -9.89306354522705, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 8.06123161315918, 'logps/rejected': -195.44522094726562, 'logps/chosen': -92.20162963867188, 'logits/rejected': -1.207153558731079, 'logits/chosen': -3.405214786529541, 'epoch': 1.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7981e82faf44e7d8e1cd4bb25a03d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8447271585464478, 'eval_runtime': 241.9125, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -4.706053733825684, 'eval_rewards/rejected': -7.380492687225342, 'eval_rewards/accuracies': 0.7297297120094299, 'eval_rewards/margins': 2.674437999725342, 'eval_logps/rejected': -164.29283142089844, 'eval_logps/chosen': -120.71488952636719, 'eval_logits/rejected': -1.6792519092559814, 'eval_logits/chosen': -3.344982862472534, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0842, 'grad_norm': 0.8671875, 'learning_rate': 1.4714659459400197e-05, 'rewards/chosen': -1.4299651384353638, 'rewards/rejected': -9.768987655639648, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.33902359008789, 'logps/rejected': -187.774658203125, 'logps/chosen': -86.75746154785156, 'logits/rejected': -0.9985278248786926, 'logits/chosen': -3.070699453353882, 'epoch': 1.42}\n",
      "{'loss': 0.0093, 'grad_norm': 0.84765625, 'learning_rate': 1.460355845458695e-05, 'rewards/chosen': -1.245634913444519, 'rewards/rejected': -9.713510513305664, 'rewards/accuracies': 1.0, 'rewards/margins': 8.467874526977539, 'logps/rejected': -185.9691162109375, 'logps/chosen': -80.33207702636719, 'logits/rejected': -1.2590669393539429, 'logits/chosen': -2.608199119567871, 'epoch': 1.44}\n",
      "{'loss': 0.035, 'grad_norm': 0.341796875, 'learning_rate': 1.4491731656246444e-05, 'rewards/chosen': -1.268381953239441, 'rewards/rejected': -9.527204513549805, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 8.25882339477539, 'logps/rejected': -180.91976928710938, 'logps/chosen': -85.7284164428711, 'logits/rejected': -1.4933760166168213, 'logits/chosen': -3.3101553916931152, 'epoch': 1.46}\n",
      "{'loss': 0.0415, 'grad_norm': 0.408203125, 'learning_rate': 1.4379196694906716e-05, 'rewards/chosen': -1.408010482788086, 'rewards/rejected': -8.810297012329102, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 7.402285575866699, 'logps/rejected': -169.60696411132812, 'logps/chosen': -85.99763488769531, 'logits/rejected': -1.5562433004379272, 'logits/chosen': -3.445219039916992, 'epoch': 1.47}\n",
      "{'loss': 0.0472, 'grad_norm': 6.03125, 'learning_rate': 1.4265971312744252e-05, 'rewards/chosen': -1.318967580795288, 'rewards/rejected': -9.571016311645508, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.252049446105957, 'logps/rejected': -184.1582489013672, 'logps/chosen': -87.62957763671875, 'logits/rejected': -1.2661106586456299, 'logits/chosen': -2.7953147888183594, 'epoch': 1.49}\n",
      "{'loss': 0.0615, 'grad_norm': 1.4375, 'learning_rate': 1.4152073360786744e-05, 'rewards/chosen': -1.1647047996520996, 'rewards/rejected': -9.322031021118164, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.157323837280273, 'logps/rejected': -179.0408172607422, 'logps/chosen': -83.60323333740234, 'logits/rejected': -1.3695685863494873, 'logits/chosen': -3.1079373359680176, 'epoch': 1.5}\n",
      "{'loss': 0.0239, 'grad_norm': 1.203125, 'learning_rate': 1.4037520796098737e-05, 'rewards/chosen': -0.997043251991272, 'rewards/rejected': -9.341482162475586, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 8.344438552856445, 'logps/rejected': -181.5624542236328, 'logps/chosen': -83.61309814453125, 'logits/rejected': -1.2151988744735718, 'logits/chosen': -2.9402599334716797, 'epoch': 1.52}\n",
      "{'loss': 0.0158, 'grad_norm': 1.1015625, 'learning_rate': 1.3922331678950525e-05, 'rewards/chosen': -1.5261716842651367, 'rewards/rejected': -9.456517219543457, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 7.930344581604004, 'logps/rejected': -179.72059631347656, 'logps/chosen': -89.23384094238281, 'logits/rejected': -1.6388803720474243, 'logits/chosen': -3.5162410736083984, 'epoch': 1.53}\n",
      "{'loss': 0.0208, 'grad_norm': 0.240234375, 'learning_rate': 1.3806524169970772e-05, 'rewards/chosen': -1.274601697921753, 'rewards/rejected': -9.336941719055176, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 8.062337875366211, 'logps/rejected': -175.1943359375, 'logps/chosen': -83.37803649902344, 'logits/rejected': -2.330787181854248, 'logits/chosen': -3.7672767639160156, 'epoch': 1.55}\n",
      "{'loss': 0.0941, 'grad_norm': 0.494140625, 'learning_rate': 1.3690116527283326e-05, 'rewards/chosen': -1.3200547695159912, 'rewards/rejected': -9.564054489135742, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.243999481201172, 'logps/rejected': -179.14212036132812, 'logps/chosen': -85.35525512695312, 'logits/rejected': -2.9654250144958496, 'logits/chosen': -4.233649730682373, 'epoch': 1.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a123167247e46a5863b05ad1019e75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7890896201133728, 'eval_runtime': 241.9429, 'eval_samples_per_second': 1.835, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -4.738537311553955, 'eval_rewards/rejected': -7.445478916168213, 'eval_rewards/accuracies': 0.7477477192878723, 'eval_rewards/margins': 2.7069408893585205, 'eval_logps/rejected': -164.9426727294922, 'eval_logps/chosen': -121.03974151611328, 'eval_logits/rejected': -2.167969226837158, 'eval_logits/chosen': -3.828482151031494, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0759, 'grad_norm': 0.126953125, 'learning_rate': 1.3573127103628666e-05, 'rewards/chosen': -1.1793973445892334, 'rewards/rejected': -9.332136154174805, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.152738571166992, 'logps/rejected': -182.75967407226562, 'logps/chosen': -85.06243896484375, 'logits/rejected': -2.7352347373962402, 'logits/chosen': -3.8798813819885254, 'epoch': 1.58}\n",
      "{'loss': 0.0268, 'grad_norm': 11.4375, 'learning_rate': 1.345557434347042e-05, 'rewards/chosen': -1.4066097736358643, 'rewards/rejected': -9.400697708129883, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 7.994089603424072, 'logps/rejected': -179.3679656982422, 'logps/chosen': -87.85325622558594, 'logits/rejected': -2.366121530532837, 'logits/chosen': -3.6166083812713623, 'epoch': 1.6}\n",
      "{'loss': 0.0324, 'grad_norm': 0.67578125, 'learning_rate': 1.3337476780087407e-05, 'rewards/chosen': -1.3526214361190796, 'rewards/rejected': -10.408535957336426, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 9.055913925170898, 'logps/rejected': -190.59312438964844, 'logps/chosen': -84.67024993896484, 'logits/rejected': -1.2124431133270264, 'logits/chosen': -2.9512414932250977, 'epoch': 1.61}\n",
      "{'loss': 0.0275, 'grad_norm': 1.0390625, 'learning_rate': 1.3218853032651719e-05, 'rewards/chosen': -1.3125572204589844, 'rewards/rejected': -9.766918182373047, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.454360961914062, 'logps/rejected': -184.9252471923828, 'logps/chosen': -88.37620544433594, 'logits/rejected': -1.2141361236572266, 'logits/chosen': -2.8637309074401855, 'epoch': 1.63}\n",
      "{'loss': 0.0514, 'grad_norm': 2.890625, 'learning_rate': 1.3099721803293223e-05, 'rewards/chosen': -1.461242437362671, 'rewards/rejected': -10.065956115722656, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.604713439941406, 'logps/rejected': -188.5436553955078, 'logps/chosen': -91.11827850341797, 'logits/rejected': -1.0668703317642212, 'logits/chosen': -3.0433428287506104, 'epoch': 1.64}\n",
      "{'loss': 0.0158, 'grad_norm': 8.5625, 'learning_rate': 1.2980101874150999e-05, 'rewards/chosen': -1.3404479026794434, 'rewards/rejected': -10.087224006652832, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 8.746776580810547, 'logps/rejected': -189.38174438476562, 'logps/chosen': -84.84333801269531, 'logits/rejected': -1.91022527217865, 'logits/chosen': -4.000796318054199, 'epoch': 1.66}\n",
      "{'loss': 0.114, 'grad_norm': 8.1875, 'learning_rate': 1.2860012104412166e-05, 'rewards/chosen': -1.6637862920761108, 'rewards/rejected': -9.67353343963623, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 8.009746551513672, 'logps/rejected': -174.54293823242188, 'logps/chosen': -91.97164154052734, 'logits/rejected': -1.7289438247680664, 'logits/chosen': -3.5048294067382812, 'epoch': 1.68}\n",
      "{'loss': 0.0153, 'grad_norm': 10.0625, 'learning_rate': 1.2739471427338552e-05, 'rewards/chosen': -1.5267219543457031, 'rewards/rejected': -10.199070930480957, 'rewards/accuracies': 1.0, 'rewards/margins': 8.672348022460938, 'logps/rejected': -195.85897827148438, 'logps/chosen': -92.79487609863281, 'logits/rejected': -1.3484046459197998, 'logits/chosen': -2.816707134246826, 'epoch': 1.69}\n",
      "{'loss': 0.023, 'grad_norm': 8.4375, 'learning_rate': 1.2618498847281694e-05, 'rewards/chosen': -1.3492119312286377, 'rewards/rejected': -10.357304573059082, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.008092880249023, 'logps/rejected': -189.4343719482422, 'logps/chosen': -88.49391174316406, 'logits/rejected': -1.0887587070465088, 'logits/chosen': -3.4479568004608154, 'epoch': 1.71}\n",
      "{'loss': 0.0332, 'grad_norm': 0.337890625, 'learning_rate': 1.2497113436686628e-05, 'rewards/chosen': -1.6309232711791992, 'rewards/rejected': -10.110822677612305, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 8.479899406433105, 'logps/rejected': -188.62271118164062, 'logps/chosen': -85.40502166748047, 'logits/rejected': -0.8334606885910034, 'logits/chosen': -2.8811259269714355, 'epoch': 1.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e22d097bd64d8daad7dbec852b6ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8847374320030212, 'eval_runtime': 241.6942, 'eval_samples_per_second': 1.837, 'eval_steps_per_second': 0.919, 'eval_rewards/chosen': -5.3233323097229, 'eval_rewards/rejected': -8.077752113342285, 'eval_rewards/accuracies': 0.7184684872627258, 'eval_rewards/margins': 2.754420042037964, 'eval_logps/rejected': -171.2654266357422, 'eval_logps/chosen': -126.88768768310547, 'eval_logits/rejected': -1.7533949613571167, 'eval_logits/chosen': -3.4619107246398926, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.094, 'grad_norm': 1.796875, 'learning_rate': 1.2375334333084932e-05, 'rewards/chosen': -1.6035562753677368, 'rewards/rejected': -10.377058029174805, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.773500442504883, 'logps/rejected': -193.09446716308594, 'logps/chosen': -86.76268768310547, 'logits/rejected': -1.6796293258666992, 'logits/chosen': -3.6540684700012207, 'epoch': 1.74}\n",
      "{'loss': 0.1447, 'grad_norm': 7.1875, 'learning_rate': 1.225318073607753e-05, 'rewards/chosen': -1.5598177909851074, 'rewards/rejected': -10.410630226135254, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 8.850812911987305, 'logps/rejected': -196.73187255859375, 'logps/chosen': -89.08562469482422, 'logits/rejected': -2.2773849964141846, 'logits/chosen': -3.9072132110595703, 'epoch': 1.75}\n",
      "{'loss': 0.0107, 'grad_norm': 1.3359375, 'learning_rate': 1.2130671904307692e-05, 'rewards/chosen': -0.9228496551513672, 'rewards/rejected': -9.89411449432373, 'rewards/accuracies': 1.0, 'rewards/margins': 8.97126579284668, 'logps/rejected': -182.70718383789062, 'logps/chosen': -80.29655456542969, 'logits/rejected': -1.929700493812561, 'logits/chosen': -3.787917375564575, 'epoch': 1.77}\n",
      "{'loss': 0.0841, 'grad_norm': 20.75, 'learning_rate': 1.2007827152424723e-05, 'rewards/chosen': -1.5651127099990845, 'rewards/rejected': -10.202753067016602, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.637639999389648, 'logps/rejected': -187.8305206298828, 'logps/chosen': -86.27954864501953, 'logits/rejected': -1.376483678817749, 'logits/chosen': -2.8016481399536133, 'epoch': 1.79}\n",
      "{'loss': 0.0204, 'grad_norm': 2.09375, 'learning_rate': 1.1884665848038844e-05, 'rewards/chosen': -0.9361389875411987, 'rewards/rejected': -9.834160804748535, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 8.898021697998047, 'logps/rejected': -187.83132934570312, 'logps/chosen': -76.16600799560547, 'logits/rejected': -2.029973268508911, 'logits/chosen': -3.5299160480499268, 'epoch': 1.8}\n",
      "{'loss': 0.0116, 'grad_norm': 4.5, 'learning_rate': 1.1761207408667702e-05, 'rewards/chosen': -1.1325727701187134, 'rewards/rejected': -10.918381690979004, 'rewards/accuracies': 1.0, 'rewards/margins': 9.785808563232422, 'logps/rejected': -199.3953399658203, 'logps/chosen': -87.54452514648438, 'logits/rejected': -2.3114330768585205, 'logits/chosen': -3.962947130203247, 'epoch': 1.82}\n",
      "{'loss': 0.019, 'grad_norm': 0.2373046875, 'learning_rate': 1.163747129867503e-05, 'rewards/chosen': -1.2836719751358032, 'rewards/rejected': -10.672170639038086, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 9.388497352600098, 'logps/rejected': -203.84768676757812, 'logps/chosen': -85.63838195800781, 'logits/rejected': -2.279749631881714, 'logits/chosen': -4.4976654052734375, 'epoch': 1.83}\n",
      "{'loss': 0.0059, 'grad_norm': 0.404296875, 'learning_rate': 1.1513477026201878e-05, 'rewards/chosen': -1.103579044342041, 'rewards/rejected': -10.612356185913086, 'rewards/accuracies': 1.0, 'rewards/margins': 9.50877571105957, 'logps/rejected': -194.90245056152344, 'logps/chosen': -85.59081268310547, 'logits/rejected': -2.1282734870910645, 'logits/chosen': -3.4467475414276123, 'epoch': 1.85}\n",
      "{'loss': 0.0114, 'grad_norm': 0.78515625, 'learning_rate': 1.1389244140091014e-05, 'rewards/chosen': -1.3397794961929321, 'rewards/rejected': -10.537907600402832, 'rewards/accuracies': 1.0, 'rewards/margins': 9.198127746582031, 'logps/rejected': -193.43643188476562, 'logps/chosen': -82.6583251953125, 'logits/rejected': -1.8562160730361938, 'logits/chosen': -3.601423740386963, 'epoch': 1.86}\n",
      "{'loss': 0.0713, 'grad_norm': 0.08251953125, 'learning_rate': 1.1264792226804846e-05, 'rewards/chosen': -1.536426305770874, 'rewards/rejected': -11.053375244140625, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 9.516948699951172, 'logps/rejected': -198.21934509277344, 'logps/chosen': -88.78874206542969, 'logits/rejected': -2.224604606628418, 'logits/chosen': -3.8162364959716797, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd93e9cc34994028a182f8ac1e310348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8103374242782593, 'eval_runtime': 241.7327, 'eval_samples_per_second': 1.837, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -5.39689826965332, 'eval_rewards/rejected': -8.190281867980957, 'eval_rewards/accuracies': 0.727477490901947, 'eval_rewards/margins': 2.7933828830718994, 'eval_logps/rejected': -172.39071655273438, 'eval_logps/chosen': -127.62334442138672, 'eval_logits/rejected': -2.213864803314209, 'eval_logits/chosen': -3.8715150356292725, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0646, 'grad_norm': 4.8125, 'learning_rate': 1.1140140907337437e-05, 'rewards/chosen': -1.4005401134490967, 'rewards/rejected': -10.798044204711914, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 9.397503852844238, 'logps/rejected': -198.8382568359375, 'logps/chosen': -85.65777587890625, 'logits/rejected': -1.882615327835083, 'logits/chosen': -3.461836576461792, 'epoch': 1.89}\n",
      "{'loss': 0.0166, 'grad_norm': 6.09375, 'learning_rate': 1.1015309834121083e-05, 'rewards/chosen': -1.4918826818466187, 'rewards/rejected': -11.159431457519531, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.667550086975098, 'logps/rejected': -197.66485595703125, 'logps/chosen': -82.3350830078125, 'logits/rejected': -2.545574188232422, 'logits/chosen': -4.18272066116333, 'epoch': 1.91}\n",
      "{'loss': 0.0437, 'grad_norm': 0.53125, 'learning_rate': 1.0890318687927912e-05, 'rewards/chosen': -1.2422250509262085, 'rewards/rejected': -10.17741870880127, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 8.93519401550293, 'logps/rejected': -195.08229064941406, 'logps/chosen': -85.412841796875, 'logits/rejected': -2.809875726699829, 'logits/chosen': -4.415456295013428, 'epoch': 1.93}\n",
      "{'loss': 0.0177, 'grad_norm': 0.4375, 'learning_rate': 1.0765187174767042e-05, 'rewards/chosen': -1.7146068811416626, 'rewards/rejected': -11.093477249145508, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.378870010375977, 'logps/rejected': -204.4980010986328, 'logps/chosen': -89.23119354248047, 'logits/rejected': -3.527388334274292, 'logits/chosen': -4.8006911277771, 'epoch': 1.94}\n",
      "{'loss': 0.0063, 'grad_norm': 1.9375, 'learning_rate': 1.0639935022777741e-05, 'rewards/chosen': -1.355299711227417, 'rewards/rejected': -10.711629867553711, 'rewards/accuracies': 1.0, 'rewards/margins': 9.356328964233398, 'logps/rejected': -199.24000549316406, 'logps/chosen': -83.98331451416016, 'logits/rejected': -2.1453182697296143, 'logits/chosen': -3.903219223022461, 'epoch': 1.96}\n",
      "{'loss': 0.0216, 'grad_norm': 2.78125, 'learning_rate': 1.0514581979119098e-05, 'rewards/chosen': -1.4192949533462524, 'rewards/rejected': -10.549077987670898, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.129781723022461, 'logps/rejected': -188.2021942138672, 'logps/chosen': -88.4021224975586, 'logits/rejected': -2.6311001777648926, 'logits/chosen': -4.239837169647217, 'epoch': 1.97}\n",
      "{'loss': 0.0537, 'grad_norm': 0.020263671875, 'learning_rate': 1.0389147806856705e-05, 'rewards/chosen': -1.3562463521957397, 'rewards/rejected': -10.35629940032959, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 9.000052452087402, 'logps/rejected': -191.37808227539062, 'logps/chosen': -84.21443176269531, 'logits/rejected': -2.254279375076294, 'logits/chosen': -3.7387306690216064, 'epoch': 1.99}\n",
      "{'loss': 0.0031, 'grad_norm': 0.1884765625, 'learning_rate': 1.0263652281846837e-05, 'rewards/chosen': -1.3943536281585693, 'rewards/rejected': -10.766088485717773, 'rewards/accuracies': 1.0, 'rewards/margins': 9.371736526489258, 'logps/rejected': -198.50054931640625, 'logps/chosen': -83.9417495727539, 'logits/rejected': -3.013000965118408, 'logits/chosen': -4.633545875549316, 'epoch': 2.0}\n",
      "{'loss': 0.0026, 'grad_norm': 0.470703125, 'learning_rate': 1.0138115189618584e-05, 'rewards/chosen': -1.3118841648101807, 'rewards/rejected': -11.445348739624023, 'rewards/accuracies': 1.0, 'rewards/margins': 10.133462905883789, 'logps/rejected': -204.49594116210938, 'logps/chosen': -87.60777282714844, 'logits/rejected': -2.221405029296875, 'logits/chosen': -3.8495354652404785, 'epoch': 2.02}\n",
      "{'loss': 0.0104, 'grad_norm': 0.00738525390625, 'learning_rate': 1.0012556322254507e-05, 'rewards/chosen': -1.3578435182571411, 'rewards/rejected': -11.52465534210205, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.1668119430542, 'logps/rejected': -206.7924041748047, 'logps/chosen': -87.49483489990234, 'logits/rejected': -3.2629852294921875, 'logits/chosen': -4.988687038421631, 'epoch': 2.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbf605cf0714a0db05e12a6f51bbc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8374937772750854, 'eval_runtime': 241.7384, 'eval_samples_per_second': 1.837, 'eval_steps_per_second': 0.918, 'eval_rewards/chosen': -5.504368305206299, 'eval_rewards/rejected': -8.476333618164062, 'eval_rewards/accuracies': 0.7454954981803894, 'eval_rewards/margins': 2.9719650745391846, 'eval_logps/rejected': -175.25123596191406, 'eval_logps/chosen': -128.6980438232422, 'eval_logits/rejected': -2.839756965637207, 'eval_logits/chosen': -4.508242130279541, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0021, 'grad_norm': 0.027099609375, 'learning_rate': 9.886995475270205e-06, 'rewards/chosen': -1.1949118375778198, 'rewards/rejected': -11.197511672973633, 'rewards/accuracies': 1.0, 'rewards/margins': 10.00260066986084, 'logps/rejected': -200.86715698242188, 'logps/chosen': -83.22762298583984, 'logits/rejected': -2.768893241882324, 'logits/chosen': -4.5776567459106445, 'epoch': 2.05}\n",
      "{'loss': 0.024, 'grad_norm': 0.025146484375, 'learning_rate': 9.761452444493389e-06, 'rewards/chosen': -1.3402456045150757, 'rewards/rejected': -11.453248023986816, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 10.113001823425293, 'logps/rejected': -200.0578155517578, 'logps/chosen': -86.02039337158203, 'logits/rejected': -2.37975811958313, 'logits/chosen': -4.374926567077637, 'epoch': 2.07}\n",
      "{'loss': 0.0079, 'grad_norm': 0.39453125, 'learning_rate': 9.635947022942876e-06, 'rewards/chosen': -1.4709943532943726, 'rewards/rejected': -11.062249183654785, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.591254234313965, 'logps/rejected': -194.42330932617188, 'logps/chosen': -85.95681762695312, 'logits/rejected': -2.908262252807617, 'logits/chosen': -4.568608283996582, 'epoch': 2.08}\n",
      "{'loss': 0.0021, 'grad_norm': 0.1923828125, 'learning_rate': 9.510498997708048e-06, 'rewards/chosen': -1.4493578672409058, 'rewards/rejected': -11.571478843688965, 'rewards/accuracies': 1.0, 'rewards/margins': 10.122119903564453, 'logps/rejected': -204.9641876220703, 'logps/chosen': -91.83782958984375, 'logits/rejected': -3.174232244491577, 'logits/chosen': -4.919233322143555, 'epoch': 2.1}\n",
      "{'loss': 0.0025, 'grad_norm': 0.31640625, 'learning_rate': 9.385128146829224e-06, 'rewards/chosen': -1.6283137798309326, 'rewards/rejected': -11.672393798828125, 'rewards/accuracies': 1.0, 'rewards/margins': 10.044079780578613, 'logps/rejected': -206.7154998779297, 'logps/chosen': -89.50672912597656, 'logits/rejected': -2.887049913406372, 'logits/chosen': -5.209826469421387, 'epoch': 2.11}\n",
      "{'loss': 0.0082, 'grad_norm': 0.140625, 'learning_rate': 9.259854236179467e-06, 'rewards/chosen': -1.7673187255859375, 'rewards/rejected': -12.077397346496582, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.310077667236328, 'logps/rejected': -212.52078247070312, 'logps/chosen': -92.69703674316406, 'logits/rejected': -3.6351821422576904, 'logits/chosen': -5.404723167419434, 'epoch': 2.13}\n",
      "{'loss': 0.0016, 'grad_norm': 0.0751953125, 'learning_rate': 9.134697016348328e-06, 'rewards/chosen': -1.8244956731796265, 'rewards/rejected': -11.560651779174805, 'rewards/accuracies': 1.0, 'rewards/margins': 9.736154556274414, 'logps/rejected': -205.04916381835938, 'logps/chosen': -91.61174011230469, 'logits/rejected': -3.2596993446350098, 'logits/chosen': -4.959923267364502, 'epoch': 2.15}\n",
      "{'loss': 0.0052, 'grad_norm': 2.015625, 'learning_rate': 9.009676219527964e-06, 'rewards/chosen': -1.989974021911621, 'rewards/rejected': -11.84872055053711, 'rewards/accuracies': 1.0, 'rewards/margins': 9.858747482299805, 'logps/rejected': -206.6095733642578, 'logps/chosen': -90.9493179321289, 'logits/rejected': -2.951246738433838, 'logits/chosen': -4.220485210418701, 'epoch': 2.16}\n",
      "{'loss': 0.001, 'grad_norm': 0.0211181640625, 'learning_rate': 8.884811556402182e-06, 'rewards/chosen': -1.6673625707626343, 'rewards/rejected': -11.80177116394043, 'rewards/accuracies': 1.0, 'rewards/margins': 10.134407043457031, 'logps/rejected': -204.4467010498047, 'logps/chosen': -86.7694091796875, 'logits/rejected': -2.6844139099121094, 'logits/chosen': -5.0048675537109375, 'epoch': 2.18}\n",
      "{'loss': 0.0026, 'grad_norm': 1.0625, 'learning_rate': 8.76012271303888e-06, 'rewards/chosen': -1.4431736469268799, 'rewards/rejected': -11.870525360107422, 'rewards/accuracies': 1.0, 'rewards/margins': 10.427351951599121, 'logps/rejected': -208.0967254638672, 'logps/chosen': -85.68769836425781, 'logits/rejected': -2.296426296234131, 'logits/chosen': -4.213257789611816, 'epoch': 2.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccad1f8b9f548c68b0ba9b164bdd6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8747154474258423, 'eval_runtime': 241.3682, 'eval_samples_per_second': 1.84, 'eval_steps_per_second': 0.92, 'eval_rewards/chosen': -6.028387546539307, 'eval_rewards/rejected': -9.119328498840332, 'eval_rewards/accuracies': 0.7364864945411682, 'eval_rewards/margins': 3.0909409523010254, 'eval_logps/rejected': -181.68118286132812, 'eval_logps/chosen': -133.938232421875, 'eval_logits/rejected': -3.388364553451538, 'eval_logits/chosen': -5.05573844909668, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.011, 'grad_norm': 0.1005859375, 'learning_rate': 8.635629347786338e-06, 'rewards/chosen': -1.7463159561157227, 'rewards/rejected': -11.586782455444336, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 9.84046745300293, 'logps/rejected': -201.5366973876953, 'logps/chosen': -90.95205688476562, 'logits/rejected': -2.6847786903381348, 'logits/chosen': -4.293046951293945, 'epoch': 2.21}\n",
      "{'loss': 0.0019, 'grad_norm': 0.040771484375, 'learning_rate': 8.511351088173904e-06, 'rewards/chosen': -2.079502582550049, 'rewards/rejected': -12.395157814025879, 'rewards/accuracies': 1.0, 'rewards/margins': 10.315653800964355, 'logps/rejected': -211.43338012695312, 'logps/chosen': -97.79947662353516, 'logits/rejected': -3.8358092308044434, 'logits/chosen': -5.289044380187988, 'epoch': 2.22}\n",
      "{'loss': 0.0067, 'grad_norm': 2.46875, 'learning_rate': 8.38730752781754e-06, 'rewards/chosen': -1.7524598836898804, 'rewards/rejected': -11.588372230529785, 'rewards/accuracies': 1.0, 'rewards/margins': 9.835912704467773, 'logps/rejected': -205.1512908935547, 'logps/chosen': -87.96556091308594, 'logits/rejected': -3.41941499710083, 'logits/chosen': -4.890773773193359, 'epoch': 2.24}\n",
      "{'loss': 0.0022, 'grad_norm': 0.034912109375, 'learning_rate': 8.263518223330698e-06, 'rewards/chosen': -1.7083215713500977, 'rewards/rejected': -12.081384658813477, 'rewards/accuracies': 1.0, 'rewards/margins': 10.373064041137695, 'logps/rejected': -212.193115234375, 'logps/chosen': -90.18645477294922, 'logits/rejected': -2.906898021697998, 'logits/chosen': -5.330602169036865, 'epoch': 2.25}\n",
      "{'loss': 0.0018, 'grad_norm': 0.0771484375, 'learning_rate': 8.140002691241044e-06, 'rewards/chosen': -1.4528801441192627, 'rewards/rejected': -12.522453308105469, 'rewards/accuracies': 1.0, 'rewards/margins': 11.069574356079102, 'logps/rejected': -213.0249786376953, 'logps/chosen': -84.0303726196289, 'logits/rejected': -4.201075553894043, 'logits/chosen': -5.864630222320557, 'epoch': 2.27}\n",
      "{'loss': 0.008, 'grad_norm': 0.2265625, 'learning_rate': 8.016780404913497e-06, 'rewards/chosen': -2.091477632522583, 'rewards/rejected': -12.903923034667969, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.812446594238281, 'logps/rejected': -219.5231475830078, 'logps/chosen': -91.7861557006836, 'logits/rejected': -2.7380497455596924, 'logits/chosen': -4.619183540344238, 'epoch': 2.29}\n",
      "{'loss': 0.0032, 'grad_norm': 0.10693359375, 'learning_rate': 7.89387079148007e-06, 'rewards/chosen': -1.548627257347107, 'rewards/rejected': -11.792576789855957, 'rewards/accuracies': 1.0, 'rewards/margins': 10.243947982788086, 'logps/rejected': -204.4972686767578, 'logps/chosen': -88.0047378540039, 'logits/rejected': -3.8977131843566895, 'logits/chosen': -5.177006244659424, 'epoch': 2.3}\n",
      "{'loss': 0.0022, 'grad_norm': 0.02294921875, 'learning_rate': 7.771293228777006e-06, 'rewards/chosen': -1.6007887125015259, 'rewards/rejected': -12.144161224365234, 'rewards/accuracies': 1.0, 'rewards/margins': 10.543371200561523, 'logps/rejected': -215.392333984375, 'logps/chosen': -90.79579162597656, 'logits/rejected': -3.9746181964874268, 'logits/chosen': -5.740236759185791, 'epoch': 2.32}\n",
      "{'loss': 0.0023, 'grad_norm': 1.171875, 'learning_rate': 7.649067042289681e-06, 'rewards/chosen': -2.025315761566162, 'rewards/rejected': -11.831130981445312, 'rewards/accuracies': 1.0, 'rewards/margins': 9.805816650390625, 'logps/rejected': -208.16903686523438, 'logps/chosen': -93.21578216552734, 'logits/rejected': -3.8516738414764404, 'logits/chosen': -4.817160606384277, 'epoch': 2.33}\n",
      "{'loss': 0.003, 'grad_norm': 0.30078125, 'learning_rate': 7.527211502105766e-06, 'rewards/chosen': -1.8002827167510986, 'rewards/rejected': -11.831275939941406, 'rewards/accuracies': 1.0, 'rewards/margins': 10.030993461608887, 'logps/rejected': -208.05642700195312, 'logps/chosen': -89.70758819580078, 'logits/rejected': -3.7504265308380127, 'logits/chosen': -5.374749183654785, 'epoch': 2.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24232bd8d55c4438a8e1f86d41d847c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8984469771385193, 'eval_runtime': 241.6385, 'eval_samples_per_second': 1.837, 'eval_steps_per_second': 0.919, 'eval_rewards/chosen': -6.081781387329102, 'eval_rewards/rejected': -9.154696464538574, 'eval_rewards/accuracies': 0.727477490901947, 'eval_rewards/margins': 3.0729153156280518, 'eval_logps/rejected': -182.03485107421875, 'eval_logps/chosen': -134.47216796875, 'eval_logits/rejected': -3.9180545806884766, 'eval_logits/chosen': -5.556198596954346, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0039, 'grad_norm': 1.2421875, 'learning_rate': 7.405745819877117e-06, 'rewards/chosen': -1.3962681293487549, 'rewards/rejected': -11.849300384521484, 'rewards/accuracies': 1.0, 'rewards/margins': 10.453032493591309, 'logps/rejected': -200.9911651611328, 'logps/chosen': -88.87690734863281, 'logits/rejected': -4.332930088043213, 'logits/chosen': -6.0395612716674805, 'epoch': 2.36}\n",
      "{'loss': 0.0028, 'grad_norm': 0.08837890625, 'learning_rate': 7.284689145790879e-06, 'rewards/chosen': -1.565704107284546, 'rewards/rejected': -11.247880935668945, 'rewards/accuracies': 1.0, 'rewards/margins': 9.682177543640137, 'logps/rejected': -192.40196228027344, 'logps/chosen': -88.87049865722656, 'logits/rejected': -4.715418815612793, 'logits/chosen': -6.456287384033203, 'epoch': 2.38}\n",
      "{'loss': 0.0017, 'grad_norm': 0.251953125, 'learning_rate': 7.164060565550287e-06, 'rewards/chosen': -1.5877081155776978, 'rewards/rejected': -11.789549827575684, 'rewards/accuracies': 1.0, 'rewards/margins': 10.20184326171875, 'logps/rejected': -211.05886840820312, 'logps/chosen': -87.38813781738281, 'logits/rejected': -4.157558441162109, 'logits/chosen': -5.633580207824707, 'epoch': 2.4}\n",
      "{'loss': 0.0103, 'grad_norm': 0.05322265625, 'learning_rate': 7.043879097365622e-06, 'rewards/chosen': -1.5129598379135132, 'rewards/rejected': -12.52027702331543, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 11.007316589355469, 'logps/rejected': -213.11398315429688, 'logps/chosen': -84.57649230957031, 'logits/rejected': -3.752103805541992, 'logits/chosen': -5.748751640319824, 'epoch': 2.41}\n",
      "{'loss': 0.0058, 'grad_norm': 0.052978515625, 'learning_rate': 6.924163688955825e-06, 'rewards/chosen': -1.6886281967163086, 'rewards/rejected': -11.89847183227539, 'rewards/accuracies': 1.0, 'rewards/margins': 10.209844589233398, 'logps/rejected': -210.1351318359375, 'logps/chosen': -89.8301010131836, 'logits/rejected': -3.3978676795959473, 'logits/chosen': -5.103480339050293, 'epoch': 2.43}\n",
      "{'loss': 0.0068, 'grad_norm': 1.5234375, 'learning_rate': 6.8049332145612045e-06, 'rewards/chosen': -1.5551975965499878, 'rewards/rejected': -12.06430435180664, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.50910758972168, 'logps/rejected': -209.4302978515625, 'logps/chosen': -85.28178405761719, 'logits/rejected': -3.5439140796661377, 'logits/chosen': -5.301356315612793, 'epoch': 2.44}\n",
      "{'loss': 0.0036, 'grad_norm': 0.04541015625, 'learning_rate': 6.686206471967729e-06, 'rewards/chosen': -1.8936532735824585, 'rewards/rejected': -12.246766090393066, 'rewards/accuracies': 1.0, 'rewards/margins': 10.353113174438477, 'logps/rejected': -213.1923370361328, 'logps/chosen': -94.2083511352539, 'logits/rejected': -2.998325824737549, 'logits/chosen': -5.340496063232422, 'epoch': 2.46}\n",
      "{'loss': 0.0012, 'grad_norm': 0.04150390625, 'learning_rate': 6.568002179543409e-06, 'rewards/chosen': -1.493601679801941, 'rewards/rejected': -12.236209869384766, 'rewards/accuracies': 1.0, 'rewards/margins': 10.742609024047852, 'logps/rejected': -207.2926025390625, 'logps/chosen': -89.5938949584961, 'logits/rejected': -4.214384078979492, 'logits/chosen': -5.791145324707031, 'epoch': 2.47}\n",
      "{'loss': 0.0319, 'grad_norm': 0.1572265625, 'learning_rate': 6.450338973287153e-06, 'rewards/chosen': -1.9071277379989624, 'rewards/rejected': -12.281197547912598, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.374070167541504, 'logps/rejected': -211.2136993408203, 'logps/chosen': -98.33836364746094, 'logits/rejected': -4.060864448547363, 'logits/chosen': -5.5189127922058105, 'epoch': 2.49}\n",
      "{'loss': 0.0269, 'grad_norm': 0.0203857421875, 'learning_rate': 6.333235403890638e-06, 'rewards/chosen': -1.5244369506835938, 'rewards/rejected': -11.974857330322266, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.450419425964355, 'logps/rejected': -204.8601531982422, 'logps/chosen': -85.73795318603516, 'logits/rejected': -4.121471881866455, 'logits/chosen': -6.096220016479492, 'epoch': 2.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9486addf8584f18bcb288c31f87259b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9451972842216492, 'eval_runtime': 241.6582, 'eval_samples_per_second': 1.837, 'eval_steps_per_second': 0.919, 'eval_rewards/chosen': -6.297119140625, 'eval_rewards/rejected': -9.26965618133545, 'eval_rewards/accuracies': 0.7252252101898193, 'eval_rewards/margins': 2.9725375175476074, 'eval_logps/rejected': -183.18447875976562, 'eval_logps/chosen': -136.6255645751953, 'eval_logits/rejected': -3.7901370525360107, 'eval_logits/chosen': -5.431327819824219, 'epoch': 2.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'grad_norm': 2.4375, 'learning_rate': 6.2167099338136095e-06, 'rewards/chosen': -1.613863229751587, 'rewards/rejected': -11.89138126373291, 'rewards/accuracies': 1.0, 'rewards/margins': 10.277518272399902, 'logps/rejected': -201.74620056152344, 'logps/chosen': -89.22239685058594, 'logits/rejected': -3.54023814201355, 'logits/chosen': -5.420180320739746, 'epoch': 2.52}\n",
      "{'loss': 0.0754, 'grad_norm': 0.107421875, 'learning_rate': 6.10078093437313e-06, 'rewards/chosen': -2.034450054168701, 'rewards/rejected': -12.459837913513184, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.42538833618164, 'logps/rejected': -217.42745971679688, 'logps/chosen': -93.59658813476562, 'logits/rejected': -3.328134536743164, 'logits/chosen': -4.7314863204956055, 'epoch': 2.54}\n",
      "{'loss': 0.0013, 'grad_norm': 0.0194091796875, 'learning_rate': 5.985466682847141e-06, 'rewards/chosen': -1.9505598545074463, 'rewards/rejected': -12.063024520874023, 'rewards/accuracies': 1.0, 'rewards/margins': 10.112464904785156, 'logps/rejected': -209.6370391845703, 'logps/chosen': -92.9891128540039, 'logits/rejected': -3.9652085304260254, 'logits/chosen': -5.485167026519775, 'epoch': 2.55}\n",
      "{'loss': 0.0007, 'grad_norm': 0.04833984375, 'learning_rate': 5.870785359592899e-06, 'rewards/chosen': -1.9408146142959595, 'rewards/rejected': -12.753244400024414, 'rewards/accuracies': 1.0, 'rewards/margins': 10.812429428100586, 'logps/rejected': -216.37997436523438, 'logps/chosen': -91.25749969482422, 'logits/rejected': -2.754485845565796, 'logits/chosen': -5.140753746032715, 'epoch': 2.57}\n",
      "{'loss': 0.0036, 'grad_norm': 0.62109375, 'learning_rate': 5.756755045180674e-06, 'rewards/chosen': -1.9923546314239502, 'rewards/rejected': -12.236346244812012, 'rewards/accuracies': 1.0, 'rewards/margins': 10.243990898132324, 'logps/rejected': -215.2954864501953, 'logps/chosen': -90.22844696044922, 'logits/rejected': -3.873296022415161, 'logits/chosen': -5.516496658325195, 'epoch': 2.58}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0380859375, 'learning_rate': 5.643393717543171e-06, 'rewards/chosen': -1.8005220890045166, 'rewards/rejected': -12.570226669311523, 'rewards/accuracies': 1.0, 'rewards/margins': 10.769704818725586, 'logps/rejected': -212.8300323486328, 'logps/chosen': -87.47465515136719, 'logits/rejected': -3.078988552093506, 'logits/chosen': -5.202413558959961, 'epoch': 2.6}\n",
      "{'loss': 0.0058, 'grad_norm': 0.6328125, 'learning_rate': 5.530719249141148e-06, 'rewards/chosen': -1.9248676300048828, 'rewards/rejected': -11.884089469909668, 'rewards/accuracies': 1.0, 'rewards/margins': 9.959220886230469, 'logps/rejected': -204.6356201171875, 'logps/chosen': -88.50236511230469, 'logits/rejected': -3.203890323638916, 'logits/chosen': -5.272616863250732, 'epoch': 2.61}\n",
      "{'loss': 0.0015, 'grad_norm': 0.0439453125, 'learning_rate': 5.418749404145666e-06, 'rewards/chosen': -1.5049515962600708, 'rewards/rejected': -11.87762451171875, 'rewards/accuracies': 1.0, 'rewards/margins': 10.372673034667969, 'logps/rejected': -200.89930725097656, 'logps/chosen': -84.31666564941406, 'logits/rejected': -4.395499229431152, 'logits/chosen': -5.811861991882324, 'epoch': 2.63}\n",
      "{'loss': 0.0011, 'grad_norm': 0.115234375, 'learning_rate': 5.307501835637388e-06, 'rewards/chosen': -1.8438663482666016, 'rewards/rejected': -12.619449615478516, 'rewards/accuracies': 1.0, 'rewards/margins': 10.775583267211914, 'logps/rejected': -221.8562469482422, 'logps/chosen': -91.67103576660156, 'logits/rejected': -3.8209738731384277, 'logits/chosen': -5.443619728088379, 'epoch': 2.65}\n",
      "{'loss': 0.0043, 'grad_norm': 0.21875, 'learning_rate': 5.196994082823419e-06, 'rewards/chosen': -1.6046584844589233, 'rewards/rejected': -11.605100631713867, 'rewards/accuracies': 1.0, 'rewards/margins': 10.000441551208496, 'logps/rejected': -197.900634765625, 'logps/chosen': -82.91475677490234, 'logits/rejected': -3.767761707305908, 'logits/chosen': -5.479966640472412, 'epoch': 2.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7515c6f108124175bd69c91eb7456f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9280789494514465, 'eval_runtime': 241.3437, 'eval_samples_per_second': 1.84, 'eval_steps_per_second': 0.92, 'eval_rewards/chosen': -6.223053455352783, 'eval_rewards/rejected': -9.315306663513184, 'eval_rewards/accuracies': 0.7319819927215576, 'eval_rewards/margins': 3.0922529697418213, 'eval_logps/rejected': -183.64097595214844, 'eval_logps/chosen': -135.88490295410156, 'eval_logits/rejected': -3.878253221511841, 'eval_logits/chosen': -5.5339202880859375, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0017, 'grad_norm': 0.310546875, 'learning_rate': 5.087243568272078e-06, 'rewards/chosen': -1.828168511390686, 'rewards/rejected': -12.077177047729492, 'rewards/accuracies': 1.0, 'rewards/margins': 10.249009132385254, 'logps/rejected': -205.72647094726562, 'logps/chosen': -92.82276153564453, 'logits/rejected': -3.938037395477295, 'logits/chosen': -5.904210567474365, 'epoch': 2.68}\n",
      "{'loss': 0.0033, 'grad_norm': 0.275390625, 'learning_rate': 4.978267595166084e-06, 'rewards/chosen': -1.7578035593032837, 'rewards/rejected': -12.09254264831543, 'rewards/accuracies': 1.0, 'rewards/margins': 10.334739685058594, 'logps/rejected': -213.3328399658203, 'logps/chosen': -86.18280029296875, 'logits/rejected': -3.532566785812378, 'logits/chosen': -5.414917945861816, 'epoch': 2.69}\n",
      "{'loss': 0.0038, 'grad_norm': 0.035400390625, 'learning_rate': 4.870083344574531e-06, 'rewards/chosen': -1.5474770069122314, 'rewards/rejected': -12.073423385620117, 'rewards/accuracies': 1.0, 'rewards/margins': 10.525947570800781, 'logps/rejected': -208.26016235351562, 'logps/chosen': -87.1566390991211, 'logits/rejected': -3.729325532913208, 'logits/chosen': -5.954136848449707, 'epoch': 2.71}\n",
      "{'loss': 0.0012, 'grad_norm': 0.049072265625, 'learning_rate': 4.762707872744152e-06, 'rewards/chosen': -1.986082673072815, 'rewards/rejected': -12.547591209411621, 'rewards/accuracies': 1.0, 'rewards/margins': 10.56151008605957, 'logps/rejected': -216.4669189453125, 'logps/chosen': -94.9600830078125, 'logits/rejected': -4.067761421203613, 'logits/chosen': -5.328145503997803, 'epoch': 2.72}\n",
      "{'loss': 0.0015, 'grad_norm': 0.51953125, 'learning_rate': 4.6561581084102296e-06, 'rewards/chosen': -1.8967775106430054, 'rewards/rejected': -12.85412883758545, 'rewards/accuracies': 1.0, 'rewards/margins': 10.957351684570312, 'logps/rejected': -214.286865234375, 'logps/chosen': -96.80445861816406, 'logits/rejected': -4.088399410247803, 'logits/chosen': -5.929963111877441, 'epoch': 2.74}\n",
      "{'loss': 0.002, 'grad_norm': 0.232421875, 'learning_rate': 4.550450850127626e-06, 'rewards/chosen': -2.232731580734253, 'rewards/rejected': -12.643542289733887, 'rewards/accuracies': 1.0, 'rewards/margins': 10.410811424255371, 'logps/rejected': -216.0601043701172, 'logps/chosen': -95.8846435546875, 'logits/rejected': -4.604477882385254, 'logits/chosen': -5.623836040496826, 'epoch': 2.76}\n",
      "{'loss': 0.0374, 'grad_norm': 0.04052734375, 'learning_rate': 4.445602763622351e-06, 'rewards/chosen': -1.8553415536880493, 'rewards/rejected': -12.404509544372559, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 10.549168586730957, 'logps/rejected': -212.46908569335938, 'logps/chosen': -90.37770080566406, 'logits/rejected': -3.5518593788146973, 'logits/chosen': -5.428295612335205, 'epoch': 2.77}\n",
      "{'loss': 0.0075, 'grad_norm': 0.1572265625, 'learning_rate': 4.341630379164035e-06, 'rewards/chosen': -1.6235322952270508, 'rewards/rejected': -12.096233367919922, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.472701072692871, 'logps/rejected': -205.88217163085938, 'logps/chosen': -84.73832702636719, 'logits/rejected': -4.072333335876465, 'logits/chosen': -6.204902648925781, 'epoch': 2.79}\n",
      "{'loss': 0.0019, 'grad_norm': 0.2275390625, 'learning_rate': 4.2385500889597965e-06, 'rewards/chosen': -1.7216144800186157, 'rewards/rejected': -12.060918807983398, 'rewards/accuracies': 1.0, 'rewards/margins': 10.339303970336914, 'logps/rejected': -207.80703735351562, 'logps/chosen': -89.7163314819336, 'logits/rejected': -3.6701502799987793, 'logits/chosen': -5.153841018676758, 'epoch': 2.8}\n",
      "{'loss': 0.0009, 'grad_norm': 0.095703125, 'learning_rate': 4.1363781445698425e-06, 'rewards/chosen': -1.8548685312271118, 'rewards/rejected': -12.394976615905762, 'rewards/accuracies': 1.0, 'rewards/margins': 10.540109634399414, 'logps/rejected': -206.94979858398438, 'logps/chosen': -89.31189727783203, 'logits/rejected': -3.6420421600341797, 'logits/chosen': -5.280844688415527, 'epoch': 2.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7b544a01b64026858c1133a5f37f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9329873919487, 'eval_runtime': 241.5419, 'eval_samples_per_second': 1.838, 'eval_steps_per_second': 0.919, 'eval_rewards/chosen': -6.304708003997803, 'eval_rewards/rejected': -9.430541038513184, 'eval_rewards/accuracies': 0.727477490901947, 'eval_rewards/margins': 3.12583327293396, 'eval_logps/rejected': -184.7933349609375, 'eval_logps/chosen': -136.70143127441406, 'eval_logits/rejected': -3.997708320617676, 'eval_logits/chosen': -5.640864372253418, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in /home/gbarbadillo/data/deepseekmath - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/gbarbadillo/miniconda3/envs/aimo/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.009, 'grad_norm': 0.2490234375, 'learning_rate': 4.03513065434528e-06, 'rewards/chosen': -1.7783300876617432, 'rewards/rejected': -13.076261520385742, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 11.297931671142578, 'logps/rejected': -223.69815063476562, 'logps/chosen': -88.68041229248047, 'logits/rejected': -4.250003814697266, 'logits/chosen': -5.50979471206665, 'epoch': 2.83}\n",
      "{'loss': 0.0084, 'grad_norm': 0.142578125, 'learning_rate': 3.934823580888473e-06, 'rewards/chosen': -1.712306261062622, 'rewards/rejected': -11.985713958740234, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 10.273408889770508, 'logps/rejected': -202.80624389648438, 'logps/chosen': -87.18635559082031, 'logits/rejected': -3.3614087104797363, 'logits/chosen': -4.8861589431762695, 'epoch': 2.85}\n",
      "{'loss': 0.0045, 'grad_norm': 0.036865234375, 'learning_rate': 3.83547273853638e-06, 'rewards/chosen': -1.8169723749160767, 'rewards/rejected': -12.242486000061035, 'rewards/accuracies': 1.0, 'rewards/margins': 10.425512313842773, 'logps/rejected': -210.3551025390625, 'logps/chosen': -93.48289489746094, 'logits/rejected': -4.046137809753418, 'logits/chosen': -6.143764972686768, 'epoch': 2.87}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 53\u001b[0m\n\u001b[1;32m     16\u001b[0m args \u001b[38;5;241m=\u001b[39m DPOConfig(\n\u001b[1;32m     17\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/hdd0/Kaggle/aimo/experiments/18_dpo/06_v1_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,               \u001b[38;5;66;03m# directory to save and repository id\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,                     \u001b[38;5;66;03m# number of training epochs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     loss_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,                    \u001b[38;5;66;03m# default value in huggingface documentation\u001b[39;00m\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m DPOTrainer(\n\u001b[1;32m     45\u001b[0m     model,\n\u001b[1;32m     46\u001b[0m     ref_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# set to none since we use peft\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     52\u001b[0m )\n\u001b[0;32m---> 53\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aimo/lib/python3.10/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aimo/lib/python3.10/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/aimo/lib/python3.10/site-packages/transformers/trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/miniconda3/envs/aimo/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:1257\u001b[0m, in \u001b[0;36mDPOTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1254\u001b[0m compute_loss_context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_peft_has_been_casted_to_bf16 \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compute_loss_context_manager():\n\u001b[0;32m-> 1257\u001b[0m     loss, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_loss_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;66;03m# Make sure to move the loss to the device the original accumulating loss is at back in the `Trainer` class:\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/aimo/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:1231\u001b[0m, in \u001b[0;36mDPOTrainer.get_batch_loss_metrics\u001b[0;34m(self, model, batch, train_eval)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     losses \u001b[38;5;241m=\u001b[39m losses \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mrpo_alpha \u001b[38;5;241m-\u001b[39m policy_chosen_logps_avg\n\u001b[1;32m   1230\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train_eval \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1231\u001b[0m metrics[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mrewards/chosen\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchosen_rewards\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1232\u001b[0m metrics[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mrewards/rejected\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m rejected_rewards\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m   1233\u001b[0m metrics[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mrewards/accuracies\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m reward_accuracies\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LoRA config based on https://github.com/ironbar/prompt_recovery/blob/main/notebooks/014_fine-tune_mistral_v2.ipynb\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.05, # 0.1, althought Vaca suggested to use 0.05 for big models\n",
    "        # r: the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters\n",
    "        r=16,\n",
    "        bias=\"none\",\n",
    "        # target_modules: The modules (for example, attention blocks) to apply the LoRA update matrices.\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# https://www.philschmid.de/dpo-align-llms-in-2024-with-trl\n",
    "# https://huggingface.co/docs/trl/main/en/dpo_trainer\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments\n",
    "args = DPOConfig(\n",
    "    output_dir=\"/mnt/hdd0/Kaggle/aimo/experiments/18_dpo/06_v1_dataset\",               # directory to save and repository id\n",
    "    num_train_epochs=4,                     # number of training epochs\n",
    "    per_device_train_batch_size=2,         # batch size per device during training\n",
    "    gradient_accumulation_steps=8,          # number of steps before performing a backward/update pass\n",
    "    per_device_eval_batch_size=2,           # batch size for evaluation\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    learning_rate=2e-5,                     # 10x higher LR than QLoRA paper\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_steps=50,                       # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"cosine\",             # use cosine learning rate scheduler\n",
    "    logging_steps=10,\n",
    "    save_steps=100,                         # when to save checkpoint\n",
    "    # save_total_limit=2,                     # limit the total amount of checkpoints\n",
    "    eval_strategy=\"steps\",                  # evaluate every n steps\n",
    "    eval_steps=100,                         # when to evaluate\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "    # tf32=True,                              # use tf32 precision\n",
    "    push_to_hub=False,                      # push model to hub\n",
    "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
    "    model_init_kwargs=None,\n",
    "    max_length=1024,\n",
    "    max_prompt_length=300,\n",
    "    beta=0.1,                               # same as huggingface documentation, default value\n",
    "    loss_type=\"sigmoid\",                    # default value in huggingface documentation\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None, # set to none since we use peft\n",
    "    peft_config=peft_config,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Count the tokens in the train set, max length and max prompt length\n",
    "- [x] Do the training parameters from the example have sense?\n",
    "- [x] Shuffle the data?\n",
    "- [x] Verify that the model generates text correctly, on the prompt recovery challenge after fine-tuning the model forgot to use the eos token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
