{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Zero-shot MMOS-DeepSeekMath-7B with self-consistency and generated code reasoning evaluation\n","\n","Self-consistency is a modification of the standard greedy decoding in reasoning pipelines via sampling several diverse answers followed by aggregation, e.g., most common answer ([SC-CoT paper](https://arxiv.org/pdf/2203.11171.pdf)).\n","\n","In this kernel, we will consider MMOS-DeepSeekMath-7B RL-tuned backbone; in my experiments, this model produces more consistent code reasoning and the code block execution will allow us to decrease arithmetic hallucinations."]},{"cell_type":"markdown","metadata":{},"source":["## References"]},{"cell_type":"markdown","metadata":{},"source":["- https://www.kaggle.com/code/ironbar/autobots-roll-out/notebook\n","- https://www.kaggle.com/code/abdurrafae/improved-code-interpretation\n","- https://kaggle.com/code/xiaoz259/pure-rng/notebook\n","- https://www.kaggle.com/code/olyatsimboy/aimo-openmath-mistral-baseline\n","- https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama\n","- https://www.kaggle.com/code/thedrcat/aimo-mixtral-baseline"]},{"cell_type":"markdown","metadata":{},"source":["## Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:19.212214Z","iopub.status.busy":"2024-05-20T07:55:19.211479Z","iopub.status.idle":"2024-05-20T07:55:19.253318Z","shell.execute_reply":"2024-05-20T07:55:19.252328Z","shell.execute_reply.started":"2024-05-20T07:55:19.212179Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    # Data parameters\n","    quick_save = False # If true it will set the time limit to 1 so the saving of the notebook is really quick\n","    submission_mode = False # If True it will use aimo.env otherwise a mock environment\n","    ## Data parameters only used when submission_mode is False\n","    dataset = '/mnt/hdd0/Kaggle/aimo/external_data/filtered_MATH_test_5.csv'\n","    problem_indices = None # If not None will restrict the evaluation to the given problem idx of the dataset\n","    # Model parameters\n","    model_path = \"/home/gbarbadillo/data/deepseekmath\"\n","    use_4bit_quantization = False\n","    balanced_device_map = True\n","    cuda_visible_devices = None # If not None could be used to limit the use of GPUS\n","    context_window_size = 4096\n","    # Run parameters\n","    time_limit = 31500 # seconds, 31500 by default which is 8.75 hours\n","    verbose = True\n","    save_results = True\n","    result_priority = ['code_answer', 'text_answer'] #['code_answer', 'boxed_answer', 'text_answer'] # Select which answers will be used as result\n","    # few-shot parameters\n","    few_shot_dataset = '/mnt/hdd0/Kaggle/aimo/external_data/MathCodeInstruct/MATHCodeInstruct_curated.csv'\n","    few_shot_samples = 0\n","    max_sample_tokens = 512 # problems with more than this tokens will be filtered\n","    max_prompt_tokens = 1024 # 3072 # only prompts with less than this tokens will be used\n","    difficulty_levels = None # levels outside this range won't be used\n","    # Inference parameters\n","    confidence_level = 0.95 # this will be used to stop sampling solutions if the difference between the first and second most voted options is significative\n","    n_repetitions = 25\n","    random_seed = None # None or int\n","    max_new_tokens = 1024 #2048\n","    max_coding_errors = 2\n","    code_output_truncate_length = 125 # max number of output parameters\n","    default_answer = 0 # this will be the response when the system does not have a valid answer\n","    # https://community.openai.com/t/cheat-sheet-mastering-temperature-and-top-p-in-chatgpt-api/172683\n","    # temperature for text generation\n","    temperature_text = 0.5\n","    top_p_text = 1.0\n","    # temperature for coding generation\n","    temperature_code = 0.5\n","    top_p_code = 1.0"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:19.255768Z","iopub.status.busy":"2024-05-20T07:55:19.255035Z","iopub.status.idle":"2024-05-20T07:55:28.405178Z","shell.execute_reply":"2024-05-20T07:55:28.403922Z","shell.execute_reply.started":"2024-05-20T07:55:19.255733Z"},"papermill":{"duration":18.075198,"end_time":"2024-02-29T09:25:25.295954","exception":false,"start_time":"2024-02-29T09:25:07.220756","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import time\n","NOTEBOOK_START_TIME = time.time()\n","\n","if CFG.use_4bit_quantization:\n","    !pip install -U /kaggle/input/accelerate-wheelwhl/accelerate-0.29.1-py3-none-any.whl -qq\n","    !pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq\n","\n","import os\n","if CFG.cuda_visible_devices is not None:\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(CFG.cuda_visible_devices)\n","    \n","import sys\n","import subprocess\n","from IPython.display import display, Markdown\n","import pandas as pd\n","from tqdm.auto import tqdm\n","import torch\n","import gc\n","import re\n","import math\n","import random\n","import json\n","from collections import Counter\n","import numpy as np\n","import tempfile\n","from pydantic import BaseModel\n","from typing import Optional\n","import datetime\n","from scipy.stats import norm\n","import glob\n","\n","# https://pytorch.org/docs/stable/backends.html#torch.backends.cuda.enable_mem_efficient_sdp\n","# Enables or disables memory efficient scaled dot product attention.\n","# If set to True I get this error: RuntimeError: cutlassF: no kernel found to launch!\n","torch.backends.cuda.enable_mem_efficient_sdp(False)\n","\n","from transformers import (\n","    AutoModelForCausalLM, \n","    AutoTokenizer, \n","    AutoConfig,\n","    StoppingCriteria,\n","    StoppingCriteriaList,\n","    set_seed\n",")\n","\n","import transformers\n","print(f\"Transformers Version: {transformers.__version__}\")\n","if CFG.random_seed is not None:\n","    set_seed(CFG.random_seed)\n","\n","import logging\n","\n","for handler in logging.root.handlers[:]:\n","    logging.root.removeHandler(handler)\n","logging.basicConfig(level=logging.INFO,\n","                    format='%(asctime)s - %(levelname)s - %(message)s')\n","logging.info('Imported all libraries.')\n","\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","plt.plot()\n","plt.close('all')\n","plt.rcParams[\"figure.figsize\"] = (20, 5)\n","mpl.rcParams['lines.linewidth'] = 3\n","mpl.rcParams['font.size'] = 16"]},{"cell_type":"markdown","metadata":{},"source":["## Code"]},{"cell_type":"markdown","metadata":{},"source":["### Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.409665Z","iopub.status.busy":"2024-05-20T07:55:28.408915Z","iopub.status.idle":"2024-05-20T07:55:28.419120Z","shell.execute_reply":"2024-05-20T07:55:28.417377Z","shell.execute_reply.started":"2024-05-20T07:55:28.409628Z"},"trusted":true},"outputs":[],"source":["class MockEnvWithDataframe:\n","    \"\"\"\n","    This class has the same interface as aimo.env, thus you can reuse the same code\n","    for making submissions or evaluating other datasets\n","    \"\"\"\n","    def __init__(self, df):\n","        \"\"\"\n","        Initializes the mock environment with a dataframe containing problems.\n","        \"\"\"\n","        self.df = df\n","        self.submissions = []\n","\n","    def iter_test(self):\n","        \"\"\"\n","        Simulates the iter_test function by yielding each problem with an accompanying sample_submission.\n","        \"\"\"\n","        for _, row in self.df.iterrows():\n","            problem = pd.DataFrame([row])\n","            sample_submission = pd.DataFrame({'id': problem.id, 'answer': [None]})\n","            yield problem, sample_submission\n","\n","    def predict(self, sample_submission):\n","        self.submissions.append(sample_submission)\n","        \n","    def get_all_submissions(self):\n","        return pd.concat(self.submissions)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.421829Z","iopub.status.busy":"2024-05-20T07:55:28.421467Z","iopub.status.idle":"2024-05-20T07:55:28.456284Z","shell.execute_reply":"2024-05-20T07:55:28.455342Z","shell.execute_reply.started":"2024-05-20T07:55:28.421803Z"},"trusted":true},"outputs":[],"source":["if CFG.submission_mode:\n","    import aimo\n","    env = aimo.make_env()\n","    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n","        N_PROBLEMS = 50\n","    else:\n","        N_PROBLEMS = 3\n","else:\n","    df = pd.read_csv(CFG.dataset)\n","    if CFG.problem_indices is not None:\n","        df = df.iloc[CFG.problem_indices].reset_index(drop=True)\n","    if 'answer' in df.columns:\n","        df['ground_truth'] = df['answer']\n","    elif CFG.dataset == '/kaggle/input/ai-mathematical-olympiad-prize/test.csv': \n","        df['ground_truth'] = 0\n","    N_PROBLEMS = len(df)\n","    display(df)\n","    env = MockEnvWithDataframe(df)\n","iter_test = env.iter_test()"]},{"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.457471Z","iopub.status.busy":"2024-05-20T07:55:28.457174Z","iopub.status.idle":"2024-05-20T07:55:28.464787Z","shell.execute_reply":"2024-05-20T07:55:28.463460Z","shell.execute_reply.started":"2024-05-20T07:55:28.457447Z"},"trusted":true},"outputs":[],"source":["class StoppingCriteriaSub(StoppingCriteria):\n","    def __init__(self, stops = [], encounters=1):\n","        super().__init__()\n","        self.stops = [stop.to(\"cuda\") for stop in stops]\n","\n","    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n","        for stop in self.stops:\n","            last_token = input_ids[0][-len(stop):]\n","            if torch.all(torch.eq(stop, last_token)):\n","                return True\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.466392Z","iopub.status.busy":"2024-05-20T07:55:28.465980Z","iopub.status.idle":"2024-05-20T07:55:28.482213Z","shell.execute_reply":"2024-05-20T07:55:28.481365Z","shell.execute_reply.started":"2024-05-20T07:55:28.466356Z"},"trusted":true},"outputs":[],"source":["def load_model(model_path, use_4bit_quantization=False):\n","    logging.info(f'Loading model: {model_path}')\n","    config = AutoConfig.from_pretrained(model_path)\n","    config.gradient_checkpointing = True # we are not training, so I believe this is irrelevant\n","    device_map = {\n","        'model.embed_tokens': 0,\n","        'model.layers.0': 0,\n","        'model.layers.1': 0,\n","        'model.layers.2': 0,\n","        'model.layers.3': 0,\n","        'model.layers.4': 0,\n","        'model.layers.5': 0,\n","        'model.layers.6': 0,\n","        'model.layers.7': 0,\n","        'model.layers.8': 0,\n","        'model.layers.9': 0,\n","        'model.layers.10': 0,\n","        'model.layers.11': 0,\n","        'model.layers.12': 0,\n","        'model.layers.13': 0,\n","        'model.layers.14': 0,\n","        'model.layers.15': 1,\n","        'model.layers.16': 1,\n","        'model.layers.17': 1,\n","        'model.layers.18': 1,\n","        'model.layers.19': 1,\n","        'model.layers.20': 1,\n","        'model.layers.21': 1,\n","        'model.layers.22': 1,\n","        'model.layers.23': 1,\n","        'model.layers.24': 1,\n","        'model.layers.25': 1,\n","        'model.layers.26': 1,\n","        'model.layers.27': 1,\n","        'model.layers.28': 1,\n","        'model.layers.29': 1,\n","        'model.norm': 1,\n","        'lm_head': 1\n","    }\n","    if not CFG.balanced_device_map or torch.cuda.device_count() < 2:\n","        device_map = 'sequential'\n","\n","    if use_4bit_quantization:\n","        from transformers import BitsAndBytesConfig\n","        quantization_config = BitsAndBytesConfig(\n","            load_in_4bit = True,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=torch.bfloat16,\n","            bnb_4bit_use_double_quant=True,\n","        )\n","    else:\n","        quantization_config = None\n","    \n","        \n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_path,\n","        device_map=device_map,\n","        torch_dtype=\"auto\", #torch.bfloat16 does not show speed differences\n","        trust_remote_code=True,\n","        quantization_config=quantization_config,\n","        config=config\n","    )\n","    model.eval()\n","    return model\n","\n","\n","def get_tokenizer(model_path):\n","    tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","    return tokenizer\n","\n","\n","def get_stopping_criteria(tokenizer, stop_words):\n","    stop_words_ids = [tokenizer(stop_word, return_tensors='pt', add_special_tokens=False)['input_ids'].squeeze() for stop_word in stop_words]\n","    stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])\n","    return stopping_criteria"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.484702Z","iopub.status.busy":"2024-05-20T07:55:28.483438Z","iopub.status.idle":"2024-05-20T07:55:28.808801Z","shell.execute_reply":"2024-05-20T07:55:28.806956Z","shell.execute_reply.started":"2024-05-20T07:55:28.484663Z"},"trusted":true},"outputs":[],"source":["tokenizer = get_tokenizer(CFG.model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.811389Z","iopub.status.busy":"2024-05-20T07:55:28.810672Z","iopub.status.idle":"2024-05-20T07:55:28.828655Z","shell.execute_reply":"2024-05-20T07:55:28.826961Z","shell.execute_reply.started":"2024-05-20T07:55:28.811349Z"},"trusted":true},"outputs":[],"source":["class TextGenerator():\n","    \"\"\"\n","    Abstraction that allows to generate text and code in different steps efficiently\n","    \"\"\"\n","    def __init__(self, cfg):\n","        self.cfg = cfg\n","        self.reset()\n","    \n","    def reset(self):\n","        self.prompt_tokens = 0\n","        self.generated_tokens = 0\n","        self.past_key_values = None\n","        self.set_generation_mode('text')\n","        self.max_new_tokens = self.cfg.max_new_tokens\n","        \n","    def set_generation_mode(self, mode):\n","        if mode == 'text':\n","            self.set_sampling_parameters(self.cfg.temperature_text, self.cfg.top_p_text)\n","        elif mode == 'code':\n","            self.set_sampling_parameters(self.cfg.temperature_code, self.cfg.top_p_code)\n","        else:\n","            raise KeyError(mode)\n","            \n","    def set_sampling_parameters(self, temperature, top_p):\n","        if temperature == 0:\n","            self.sampling_parameters = dict(do_sample=False)\n","        else:\n","            self.sampling_parameters = dict(do_sample=True, temperature=temperature, top_p=top_p)\n","            \n","    def are_generation_tokens_available(self):\n","        return self.generated_tokens < self.max_new_tokens\n","    \n","    def verify_max_new_tokens(self):\n","        if self.max_new_tokens > self.cfg.context_window_size - self.prompt_tokens:\n","            self.max_new_tokens = self.cfg.context_window_size - self.prompt_tokens\n","            logging.warning(f'Reducing max_new_tokens to {self.max_new_tokens} to avoid exceeding the context window of {self.cfg.context_window_size}')\n","        \n","    def generate(self, prompt, mode='text'):\n","        self.set_generation_mode(mode)\n","        model_inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n","        if self.prompt_tokens == 0:\n","            self.prompt_tokens = len(model_inputs['input_ids'][0])\n","            logging.info(f'Prompt has {self.prompt_tokens} tokens.')\n","            self.verify_max_new_tokens()\n","        self.generated_tokens = len(model_inputs['input_ids'][0]) - self.prompt_tokens\n","        if not self.are_generation_tokens_available():\n","            logging.warning(f'Input text exceeded the available generation tokens. This is likely happening because a big code output.')\n","            return prompt\n","        \n","        t0 = time.time()\n","        clear_memory()\n","        generation_output = model.generate(\n","            **model_inputs, \n","            max_new_tokens=self.max_new_tokens - self.generated_tokens,\n","            past_key_values=self.past_key_values,\n","            return_dict_in_generate=True,\n","            num_return_sequences=1,\n","            stopping_criteria=stopping_criteria,\n","            pad_token_id=tokenizer.eos_token_id,\n","            **self.sampling_parameters\n","            )\n","        output_ids = generation_output.sequences[0]\n","        newly_generated_tokens = len(output_ids) - len(model_inputs['input_ids'][0])\n","        self.generated_tokens = len(output_ids) - self.prompt_tokens\n","        logging.info(f'Generating {mode} speed: {newly_generated_tokens/(time.time() - t0):.1f} tokens/s ({newly_generated_tokens}) ({self.generated_tokens}/{self.max_new_tokens})')\n","        self.past_key_values = generation_output.past_key_values\n","        decoded_output = tokenizer.decode(output_ids, skip_special_tokens=True)\n","        return decoded_output\n","    \n","    def __call__(self, prompt, mode):\n","        return self.generate(prompt, mode)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.832361Z","iopub.status.busy":"2024-05-20T07:55:28.831290Z","iopub.status.idle":"2024-05-20T07:55:28.849295Z","shell.execute_reply":"2024-05-20T07:55:28.847497Z","shell.execute_reply.started":"2024-05-20T07:55:28.832306Z"},"trusted":true},"outputs":[],"source":["def log_gpu_memory():\n","    for device in range(torch.cuda.device_count()):\n","        logging.info(f'GPU {device} memory allocated: {torch.cuda.memory_allocated(device)/1024**3:.1f} GB, max memory allocated: {torch.cuda.max_memory_allocated(device)/1024**3:.1f} GB')\n","        \n","def empty_gpu_vram():\n","    logging.info('Emptying GPU VRAM...')\n","    global model, tokenizer\n","    del model\n","    del tokenizer\n","    gc.collect()\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","    log_gpu_memory()\n","\n","log_gpu_memory()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.854855Z","iopub.status.busy":"2024-05-20T07:55:28.854028Z","iopub.status.idle":"2024-05-20T07:55:28.865935Z","shell.execute_reply":"2024-05-20T07:55:28.864838Z","shell.execute_reply.started":"2024-05-20T07:55:28.854820Z"},"trusted":true},"outputs":[],"source":["def create_model_and_inference_artifacts():\n","    global model, text_generator, stop_words, stopping_criteria\n","    if 'model' in globals():\n","        return\n","    model = load_model(CFG.model_path, use_4bit_quantization=CFG.use_4bit_quantization)\n","    stop_words = [\"```output\", \"```python\", \"```\\nOutput\" , \")\\n```\" , \"``````output\", 'Problem:']\n","    stopping_criteria = get_stopping_criteria(tokenizer, stop_words)\n","    text_generator = TextGenerator(cfg=CFG)\n","    log_gpu_memory()"]},{"cell_type":"markdown","metadata":{},"source":["### Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.867892Z","iopub.status.busy":"2024-05-20T07:55:28.867482Z","iopub.status.idle":"2024-05-20T07:55:28.876669Z","shell.execute_reply":"2024-05-20T07:55:28.875631Z","shell.execute_reply.started":"2024-05-20T07:55:28.867863Z"},"trusted":true},"outputs":[],"source":["def clear_memory():\n","    for _ in range(2):\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        time.sleep(0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.879128Z","iopub.status.busy":"2024-05-20T07:55:28.878070Z","iopub.status.idle":"2024-05-20T07:55:28.890647Z","shell.execute_reply":"2024-05-20T07:55:28.889569Z","shell.execute_reply.started":"2024-05-20T07:55:28.879088Z"},"trusted":true},"outputs":[],"source":["def is_ending_time(max_time=CFG.time_limit):\n","    is_ending_time = get_time_spent() > max_time\n","    if is_ending_time:\n","        logging.warning('Reached limit time, inference will be skipped.')\n","    return is_ending_time\n","\n","def get_time_spent():\n","    return time.time() - NOTEBOOK_START_TIME\n","\n","assert not is_ending_time(100)\n","assert is_ending_time(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.893399Z","iopub.status.busy":"2024-05-20T07:55:28.891994Z","iopub.status.idle":"2024-05-20T07:55:28.902254Z","shell.execute_reply":"2024-05-20T07:55:28.901298Z","shell.execute_reply.started":"2024-05-20T07:55:28.893349Z"},"trusted":true},"outputs":[],"source":["def is_quick_save_condition(idx, test):\n","    if CFG.quick_save and idx == 0 and CFG.submission_mode:\n","        if test['id'].values[0] == '000aaa':\n","            if test['problem'].values[0] == 'What is $1-1$?':\n","                logging.info('Quick save condition reached. Skipping inference')\n","                return True\n","    return False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.904059Z","iopub.status.busy":"2024-05-20T07:55:28.903568Z","iopub.status.idle":"2024-05-20T07:55:28.922142Z","shell.execute_reply":"2024-05-20T07:55:28.920991Z","shell.execute_reply.started":"2024-05-20T07:55:28.904033Z"},"trusted":true},"outputs":[],"source":["def get_timestamp():\n","    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n","\n","print(get_timestamp())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.924197Z","iopub.status.busy":"2024-05-20T07:55:28.923616Z","iopub.status.idle":"2024-05-20T07:55:28.933862Z","shell.execute_reply":"2024-05-20T07:55:28.932892Z","shell.execute_reply.started":"2024-05-20T07:55:28.924164Z"},"trusted":true},"outputs":[],"source":["N_REPETITIONS = CFG.n_repetitions\n","\n","PROBLEM_REPETITIONS = []\n","\n","def adjust_repetitions_to_meet_ending_time(answered_problems,\n","                                           max_time=CFG.time_limit,\n","                                           min_problem_threshold=5,\n","                                           hysteresis=0.975):\n","    global N_REPETITIONS, PROBLEM_REPETITIONS\n","    PROBLEM_REPETITIONS.append(N_REPETITIONS)\n","    if answered_problems < min_problem_threshold:\n","        return\n","    spent_time = get_time_spent()\n","    mean_problem_time = spent_time/sum(PROBLEM_REPETITIONS)\n","    estimated_ending_time = (N_PROBLEMS - answered_problems)*mean_problem_time*N_REPETITIONS + spent_time\n","    logging.info(f'Mean problem time: {mean_problem_time:.1f} seconds, estimated ending time {estimated_ending_time/3600:.1f} hours')\n","    if estimated_ending_time > max_time and N_REPETITIONS > 1:\n","        N_REPETITIONS -= 1\n","        logging.warning(f'Decreasing the number of repetitions to {N_REPETITIONS} to try to meet ending time')\n","    elif estimated_ending_time < max_time*hysteresis and N_REPETITIONS < CFG.n_repetitions:\n","        N_REPETITIONS += 1\n","        logging.warning(f'Increasing the number of repetitions to {N_REPETITIONS} because it seems to be enough time to meet the ending time')"]},{"cell_type":"markdown","metadata":{},"source":["### Response parsing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.935944Z","iopub.status.busy":"2024-05-20T07:55:28.935030Z","iopub.status.idle":"2024-05-20T07:55:28.950352Z","shell.execute_reply":"2024-05-20T07:55:28.949341Z","shell.execute_reply.started":"2024-05-20T07:55:28.935906Z"},"trusted":true},"outputs":[],"source":["def text_to_int_answer(text):\n","    try:\n","        answer = float(text)\n","        if answer < 0 or not answer.is_integer():\n","            return None\n","        return int(answer)\n","    except (ValueError, OverflowError):\n","        return None\n","\n","assert 5 == text_to_int_answer('5')\n","assert 5 == text_to_int_answer('5.0')\n","assert text_to_int_answer('-1') is None\n","assert text_to_int_answer('0.5') is None\n","assert text_to_int_answer('pi') is None"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.952729Z","iopub.status.busy":"2024-05-20T07:55:28.951475Z","iopub.status.idle":"2024-05-20T07:55:28.963873Z","shell.execute_reply":"2024-05-20T07:55:28.962351Z","shell.execute_reply.started":"2024-05-20T07:55:28.952688Z"},"trusted":true},"outputs":[],"source":["def parse_boxed_answer(text):\n","    matches = re.findall(r'\\\\boxed\\{(\\d+)\\}', text)\n","    if matches:\n","        return text_to_int_answer(matches[-1])\n","    return None\n","\n","test_text = \"\"\"\n","\n","blah blah \\\\boxed{5} 7\n","\"\"\"\n","assert parse_boxed_answer(test_text) == 5\n","\n","test_text = \"\"\"\n","\n","blah blah {5} 7\n","\"\"\"\n","assert parse_boxed_answer(test_text) == None"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.966352Z","iopub.status.busy":"2024-05-20T07:55:28.965235Z","iopub.status.idle":"2024-05-20T07:55:28.981380Z","shell.execute_reply":"2024-05-20T07:55:28.979872Z","shell.execute_reply.started":"2024-05-20T07:55:28.966309Z"},"trusted":true},"outputs":[],"source":["def parse_response_in_text(text):\n","    response = parse_boxed_answer(text)\n","    if response is not None:\n","        return response\n","    return parse_last_answer(text)\n","\n","def parse_last_answer(text):\n","    pattern = r'(?:the answer is|the final answer is)\\s*:?\\s*\\$?(\\d+(\\.\\d+)?)\\$?'\n","    matches = re.findall(pattern, text, re.IGNORECASE)\n","    if matches:\n","        return text_to_int_answer(matches[-1][0])\n","    return None\n","\n","test_cases = [\n","    ('The answer is: $651$', 651),\n","    ('The answer is: $5$.', 5),\n","    ('The answer is: 6.', 6),\n","    ('The final answer is 0.', 0),\n","    ('The final answer is 126.', 126),\n","    ('The final answer is: $2$.', 2),\n","    ('The answer is $\\\\boxed{3}$', 3),\n","    ('The answer is $\\\\boxed{-1}$', None),\n","    ('The answer is $\\\\boxed{1.5}$', None),\n","    ('The answer is: $-1$.', None),\n","    ('The answer is: $4.5$.', None),\n","    ('The final answer is 0.6', None),\n","]\n","for text, answer in test_cases:\n","    assert parse_response_in_text(text) == answer\n","    assert parse_response_in_text(text.lower()) == answer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-20T07:55:28.983758Z","iopub.status.busy":"2024-05-20T07:55:28.982953Z","iopub.status.idle":"2024-05-20T07:55:28.995360Z","shell.execute_reply":"2024-05-20T07:55:28.993903Z","shell.execute_reply.started":"2024-05-20T07:55:28.983726Z"},"trusted":true},"outputs":[],"source":["def parse_response_in_code(code_output):\n","    if code_output is None:\n","        return None\n","    try:\n","        code_output = code_output.strip()\n","        if code_output.startswith('[') and code_output.endswith(']'):\n","            return text_to_int_answer(code_output[1:-1])\n","        return text_to_int_answer(code_output)\n","    except Exception as e:\n","        print(f'Exception when trying to get a response from code: {e}')\n","        return None\n","    \n","assert parse_response_in_code('0') == 0\n","assert parse_response_in_code('[0]') == 0"]},{"cell_type":"markdown","metadata":{},"source":["### Code interpreter"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.491888Z","iopub.status.idle":"2024-05-20T07:55:29.492897Z","shell.execute_reply":"2024-05-20T07:55:29.492621Z","shell.execute_reply.started":"2024-05-20T07:55:29.492595Z"},"trusted":true},"outputs":[],"source":["def code_interpreter(code):\n","    code = preprocess_code(code)\n","    output, run_success = execute_code(code)\n","    return output, run_success\n","\n","def preprocess_code(code):\n","    code = ensure_symbols_are_real(code)\n","    code = add_simplify_to_print(code)\n","    code = f'from sympy import *\\n{code}'\n","    return code\n","\n","def add_simplify_to_print(code):\n","    code = code.replace('print(', 'simplify_print(')\n","    new_code = \"\"\"\n","def simplify_print(x):\n","    print(recursive_simplify(x))\n","        \n","def recursive_simplify(x):\n","    if isinstance(x, list):\n","        return [recursive_simplify(y) for y in x]\n","    return simplify(x)\n","\"\"\"\n","    code = new_code + '\\n' + code\n","    return code\n","\n","def ensure_symbols_are_real(code):\n","    def replace_symbols_call(match):\n","        matched_text = match.group()\n","        if \"real\" not in matched_text:\n","            return f\"{matched_text[:-1]}, real=True)\"\n","        else:\n","            return matched_text\n","    code = re.sub(r\"symbols\\([^)]+\\)\", replace_symbols_call, code)\n","    return code\n","\n","assert ensure_symbols_are_real(\"x, y, z = symbols('x y z')\") == \"x, y, z = symbols('x y z', real=True)\"\n","assert ensure_symbols_are_real(\"x, y, z = symbols('x y z', real=True)\") == \"x, y, z = symbols('x y z', real=True)\"\n","\n","def execute_code(code, timeout_limit=7):\n","    with tempfile.NamedTemporaryFile(mode='w+', delete=False) as temp_file:\n","        temp_file.write(code)\n","        temp_filepath = temp_file.name\n","    cmd = f'timeout {timeout_limit} {sys.executable} {temp_filepath}'\n","    ret = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n","    os.remove(temp_filepath)\n","    if ret.returncode == 0:\n","        return truncate_text(get_last_line(ret.stdout)), True\n","    elif ret.returncode == 124:\n","        return f'The execution of the code timeout. The code needs to run in less than {timeout_limit} seconds.', False\n","    else:\n","        #output = remove_references_to_temp_code_file(ret.stderr, temp_filepath)\n","        output = truncate_text(get_last_line(ret.stderr))\n","        return output, False\n","    \n","def remove_references_to_temp_code_file(output, filepath):\n","    return output.replace(f'File \"{filepath}\", ', '')\n","\n","def get_last_line(text):\n","    lines = text.strip().splitlines()\n","    if lines:\n","        return lines[-1]\n","    return text.strip()\n","\n","def truncate_text(text, max_length=CFG.code_output_truncate_length):\n","    \"\"\"Sometimes code output can be very long\"\"\"\n","    if len(text) > max_length:\n","        return text[:max_length] + '...'\n","    return text\n","\n","test_code = \"\"\"\n","print('Hello')\n","\"\"\"\n","print(code_interpreter('print(0)'))\n","print(code_interpreter('foo'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.494193Z","iopub.status.idle":"2024-05-20T07:55:29.495291Z","shell.execute_reply":"2024-05-20T07:55:29.495046Z","shell.execute_reply.started":"2024-05-20T07:55:29.495024Z"},"trusted":true},"outputs":[],"source":["test_code = \"\"\"\n","from sympy import symbols, Eq, solve\n","\n","def solve_equation():\n","    x = symbols('x')\n","    equation = Eq(4 + x, 4)\n","    solution = solve(equation, x)\n","\n","    return solution\n","\n","result = solve_equation()\n","print(result)\n","\"\"\"\n","print(code_interpreter(test_code))\n","\n","test_code = \"\"\"\n","from sympy import symbols, Eq, solve\n","\n","def solve_equation():\n","    x = symbols('x', real=True)\n","    equation = Eq(4 + x, 4)\n","    solution = solve(equation, x)\n","\n","    return solution\n","\n","result = solve_equation()\n","print(result)\n","\"\"\"\n","print(code_interpreter(test_code))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.496577Z","iopub.status.idle":"2024-05-20T07:55:29.497484Z","shell.execute_reply":"2024-05-20T07:55:29.497218Z","shell.execute_reply.started":"2024-05-20T07:55:29.497195Z"},"trusted":true},"outputs":[],"source":["def parse_last_python_code_block(text):\n","    return text.split('```python')[-1].split(\"```\")[0]\n","\n","test_text = \"\"\"\n","```python\n","hello\n","``````output\n","\"\"\"\n","assert parse_last_python_code_block(test_text) == '\\nhello\\n'\n","\n","test_text = \"\"\"\n","```python\n","hello\n","```\n","\"\"\"\n","assert parse_last_python_code_block(test_text) == '\\nhello\\n'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.499213Z","iopub.status.idle":"2024-05-20T07:55:29.500283Z","shell.execute_reply":"2024-05-20T07:55:29.499933Z","shell.execute_reply.started":"2024-05-20T07:55:29.499908Z"},"trusted":true},"outputs":[],"source":["def add_code_output_to_prompt(decoded_output, code_output):\n","    if decoded_output.endswith(\")\\n```\"):\n","        prompt = decoded_output+'```output\\n'+str(code_output)+'\\n```\\n'\n","    else:\n","        prompt = decoded_output+'\\n'+str(code_output)+'\\n```\\n'\n","    return prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.502157Z","iopub.status.idle":"2024-05-20T07:55:29.502562Z","shell.execute_reply":"2024-05-20T07:55:29.502383Z","shell.execute_reply.started":"2024-05-20T07:55:29.502368Z"},"trusted":true},"outputs":[],"source":["class CodeRunner():\n","    \"\"\"\n","    Abstraction to run code that:\n","    \n","    - Accumulates the code if the runs are succesfull\n","    - Measures number of coding errors\n","    \"\"\"\n","    def __init__(self, max_coding_errors=2):\n","        self.accumulated_code = ''\n","        self.n_coding_errors = 0\n","        self.successful_code_output = None\n","        self.max_coding_errors = max_coding_errors\n","        self.code_interpreter_calls = 0\n","    \n","    def run_code(self, code):\n","        self.code_interpreter_calls += 1\n","        new_code = self.accumulated_code + \"\\n\" + code\n","        code_output, run_success = code_interpreter(new_code)\n","        if run_success:\n","            self.accumulated_code = new_code\n","            self.successful_code_output = code_output\n","        else:\n","            self.n_coding_errors += 1\n","            self.successful_code_output = None\n","        return code_output\n","    \n","    def max_coding_errors_reached(self):\n","        max_coding_errors_reached = self.n_coding_errors >= self.max_coding_errors\n","        if max_coding_errors_reached:\n","            logging.warning(f'Stopping solution generation because {self.n_coding_errors} coding errors were done.')\n","        return max_coding_errors_reached"]},{"cell_type":"markdown","metadata":{},"source":["### Prompts"]},{"cell_type":"markdown","metadata":{},"source":["#### Define problems"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.504405Z","iopub.status.idle":"2024-05-20T07:55:29.505297Z","shell.execute_reply":"2024-05-20T07:55:29.505042Z","shell.execute_reply.started":"2024-05-20T07:55:29.505019Z"},"trusted":true},"outputs":[],"source":["prompts_df = pd.read_csv(CFG.few_shot_dataset)\n","prompts_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.506939Z","iopub.status.idle":"2024-05-20T07:55:29.507489Z","shell.execute_reply":"2024-05-20T07:55:29.507242Z","shell.execute_reply.started":"2024-05-20T07:55:29.507221Z"},"trusted":true},"outputs":[],"source":["logging.info(f'The number of problems for few-shot prompting is {len(prompts_df)} previous to filtering')\n","logging.info(f'Filtering problems longer than {CFG.max_sample_tokens} tokens and outside levels {CFG.difficulty_levels}')\n","prompts_df = prompts_df[prompts_df.total_tokens < CFG.max_sample_tokens]\n","if CFG.difficulty_levels is not None:\n","    prompts_df = prompts_df[prompts_df.level.isin([f'Level {i}' for i in CFG.difficulty_levels])]\n","prompts_df.reset_index(drop=True, inplace=True)\n","logging.info(f'The number of problems for few-shot prompting is {len(prompts_df)} after filtering')"]},{"cell_type":"markdown","metadata":{},"source":["#### Create prompts"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.509588Z","iopub.status.idle":"2024-05-20T07:55:29.510143Z","shell.execute_reply":"2024-05-20T07:55:29.509888Z","shell.execute_reply.started":"2024-05-20T07:55:29.509866Z"},"trusted":true},"outputs":[],"source":["# https://github.com/deepseek-ai/DeepSeek-Math/tree/main\n","# this first template was used with the original MATH dataset\n","problem_prompt = \"\"\"\n","Problem:\n","\n","QUESTION_PLACEHOLDER\n","\n","Please reason step by step, and always end with \"The final answer is $\\\\boxed{}$\".\n","The answer must be an integer greater or equal to zero.\n","\n","ANSWER_PLACEHOLDER\n","\"\"\"\n","\n","# this other template is designed to \n","problem_prompt = \"\"\"\n","Problem:\n","\n","QUESTION_PLACEHOLDER\n","\n","You are an expert mathematical programmer. Solve the above mathematical problem by writing a Python program.\n","Express your answer as a numeric type or a SymPy object. The answer must be an integer greater or equal to zero.\n","Please reason step by step, and always end with \"The final answer is $\\\\boxed{}$\".\n","\n","ANSWER_PLACEHOLDER\n","\"\"\"\n","\n","\n","def create_random_few_shot_prompt(n=CFG.few_shot_samples):\n","    prompt = ''\n","    problem_indices = np.random.choice(np.arange(len(prompts_df)), n, replace=False)\n","    for problem_idx in problem_indices:\n","        row = prompts_df.loc[problem_idx]\n","        prompt += problem_prompt.replace('QUESTION_PLACEHOLDER', row['problem']).replace('ANSWER_PLACEHOLDER', row['solution'])\n","        prompt += f'\\nThe final answer is $\\\\boxed{{{row[\"answer\"]}}}$\\n'\n","    prompt += problem_prompt.replace('QUESTION_PLACEHOLDER', 'PROBLEM_PLACEHOLDER').replace('ANSWER_PLACEHOLDER', '')\n","    return prompt.strip()\n","\n","def create_random_few_shot_prompt_with_token_limit(token_limit=CFG.max_prompt_tokens):\n","    while 1:\n","        prompt = create_random_few_shot_prompt()\n","        if len(tokenizer.tokenize(prompt)) < token_limit:\n","            return prompt\n","\n","\n","prompt = create_random_few_shot_prompt_with_token_limit()\n","print(f'Number of tokens in prompt: {len(tokenizer.tokenize(prompt))}')\n","display(Markdown(prompt))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.512753Z","iopub.status.idle":"2024-05-20T07:55:29.513429Z","shell.execute_reply":"2024-05-20T07:55:29.513217Z","shell.execute_reply.started":"2024-05-20T07:55:29.513194Z"},"trusted":true},"outputs":[],"source":["%%time\n","print('Create some random prompts to see token length distribution')\n","[len(tokenizer.tokenize(create_random_few_shot_prompt_with_token_limit())) for _ in range(10)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.514623Z","iopub.status.idle":"2024-05-20T07:55:29.515035Z","shell.execute_reply":"2024-05-20T07:55:29.514862Z","shell.execute_reply.started":"2024-05-20T07:55:29.514847Z"},"trusted":true},"outputs":[],"source":["def get_formatted_prompt(problem, repetition_idx):\n","    prompt = create_random_few_shot_prompt()\n","    # prompt = prompt_options[repetition_idx % len(prompt_options)]\n","    prompt = prompt.replace('PROBLEM_PLACEHOLDER', problem)\n","    return prompt"]},{"cell_type":"markdown","metadata":{},"source":["#### Simpler prompts"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.516754Z","iopub.status.idle":"2024-05-20T07:55:29.517154Z","shell.execute_reply":"2024-05-20T07:55:29.516985Z","shell.execute_reply.started":"2024-05-20T07:55:29.516969Z"},"trusted":true},"outputs":[],"source":["code_prompt = \"\"\"Below is a math problem you are to solve (non negative integer answer):\n","\n","\\\"PROBLEM_PLACEHOLDER\\\"\n","\n","To accomplish this, first determine a sympy-based approach for solving the problem by listing each step to take and what functions need to be called in each step. Be clear so even an idiot can follow your instructions, and remember, your final answer should be a non negative integer, not an algebraic expression!\n","Write the entire script covering all the steps (use comments and document it well) and print the result. After solving the problem, output the final numerical answer within \\\\boxed{}.\n","\n","Approach:\n","\n","```python\"\"\"\n","\n","\n","cot_prompt = \"\"\"Below is a math problem you are to solve (non negative integer answer):\n","\n","\\\"PROBLEM_PLACEHOLDER\\\"\n","\n","Analyze this problem and think step by step to come to a solution with programs. After solving the problem, output the final numerical answer within \\\\boxed{}.\n","\n","```python\"\"\"\n","\n","custom_prompt_1 = \"\"\"\n","You are an expert mathematical programmer. Solve the mathematical problem below by writing a Python program.\n","Express your answer as a numeric type or a sympy object. The answer must be an integer greater or equal to zero.\n","Please reason step by step, and write clean and readable code.\n","You can use python libraries such as sympy, math or numpy to solve the problem.\n","\n","PROBLEM_PLACEHOLDER\n","\n","Sure, let's write a python script that solves the problem step by step.\n","\n","```python\"\"\"\n","\n","custom_prompt_2 = \"\"\"PROBLEM_PLACEHOLDER\n","\n","You are an expert mathematical programmer. Solve the above mathematical problem by writing a Python program.\n","Express your answer as a numeric type or a sympy object. The answer must be an integer greater or equal to zero.\n","Please reason step by step, and write clean and readable code.\n","You can use python libraries such as sympy, math or numpy to solve the problem.\n","\n","```python\"\"\"\n","\n","prompt_options = [custom_prompt_1, custom_prompt_2]\n","\n","def get_formatted_prompt(problem, repetition_idx):\n","    prompt = prompt_options[repetition_idx % len(prompt_options)]\n","    prompt = prompt.replace('PROBLEM_PLACEHOLDER', problem)\n","    return prompt"]},{"cell_type":"markdown","metadata":{},"source":["### Results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.518714Z","iopub.status.idle":"2024-05-20T07:55:29.519093Z","shell.execute_reply":"2024-05-20T07:55:29.518932Z","shell.execute_reply.started":"2024-05-20T07:55:29.518917Z"},"trusted":true},"outputs":[],"source":["class InferenceResult(BaseModel):\n","    # text\n","    prompt: str\n","    response: Optional[str] = None\n","    # answers\n","    boxed_answer: Optional[int] = None\n","    text_answer: Optional[int] = None\n","    code_answer: Optional[int] = None\n","    # output\n","    output_tokens: int = 0\n","    reached_max_tokens: bool = False\n","    # code\n","    coding_errors: int = 0\n","    code_interpreter_calls: int = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.520147Z","iopub.status.idle":"2024-05-20T07:55:29.520548Z","shell.execute_reply":"2024-05-20T07:55:29.520358Z","shell.execute_reply.started":"2024-05-20T07:55:29.520343Z"},"trusted":true},"outputs":[],"source":["def is_difference_significative(n_first, n_second, n_tries, confidence_level=CFG.confidence_level):\n","    if n_second == 0:\n","        if n_first == n_tries:\n","            return is_difference_significative(n_first, 1, n_tries + 1, confidence_level)\n","        elif n_first < n_tries:\n","            return is_difference_significative(n_first, 1, n_tries, confidence_level)\n","        else:\n","            raise ValueError()\n","    p_first = n_first/n_tries\n","    p_second = n_second/n_tries\n","    uncertainty = (p_first*(1-p_first)/n_tries + p_second*(1-p_second)/n_tries)**0.5\n","    z = (p_first - p_second)/uncertainty\n","    logging.info(f'p_first: {p_first*100:.1f}% p_second: {p_second*100:.1f}% Confidence level for the difference: {2*(norm.cdf(z) - 0.5)*100:.1f}%')\n","    return z > norm.interval(confidence_level)[1]\n","\n","is_difference_significative(3, 0, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.522963Z","iopub.status.idle":"2024-05-20T07:55:29.523638Z","shell.execute_reply":"2024-05-20T07:55:29.523418Z","shell.execute_reply.started":"2024-05-20T07:55:29.523399Z"},"trusted":true},"outputs":[],"source":["def log_ground_truth(idx):\n","    if isinstance(env, MockEnvWithDataframe) and 'ground_truth' in df.columns:\n","        logging.info(f'Ground truth: {df[\"ground_truth\"].loc[idx]}')\n","\n","class Results():\n","    def __init__(self):\n","        self.results = dict()\n","\n","    def initialize(self, idx):\n","        self.results[idx] = []\n","\n","    def add_result(self, idx, result: InferenceResult):\n","        self.results[idx].append(result)\n","    \n","    def log_results_distribution(self, idx):\n","        log_ground_truth(idx)\n","        keys = ['boxed_answer', 'text_answer', 'code_answer']\n","        for key in keys:\n","            values = self.get_result_distribution(idx, key)\n","            logging.info(f'{key} distribution: {values}')\n","\n","    def get_valid_results(self, idx, result_priority):\n","        results = []\n","        for result in self.results[idx]:\n","            result = result.dict()\n","            for key in result_priority:\n","                if result[key] is not None:\n","                    results.append(result[key])\n","                    break\n","        if results:\n","            return results\n","        raise NoValidResults(idx)\n","\n","    def get_most_frequent_result(self, idx, result_priority=CFG.result_priority):\n","        valid_results = self.get_valid_results(idx, result_priority)\n","        counter_ret = Counter(valid_results).most_common()\n","        logging.info(f'Result counts for {idx}: {counter_ret}')\n","        result, count = get_minimum_most_frequent_value(counter_ret)\n","        return result, count\n","\n","    def is_best_solution_found(self, idx, result_priority=CFG.result_priority):\n","        try:\n","            valid_results = self.get_valid_results(idx, result_priority)\n","            counter_ret = Counter(valid_results).most_common()\n","            logging.info(f'Result counts for {idx}: {counter_ret}')\n","            if len(counter_ret) == 1:\n","                return is_difference_significative(counter_ret[0][1], 0, len(valid_results))\n","            else:\n","                return is_difference_significative(counter_ret[0][1], counter_ret[1][1], len(valid_results))\n","        except NoValidResults:\n","            return False\n","\n","    def get_result_distribution(self, idx, key):\n","        results = self.results[idx]\n","        distribution = np.array([result.dict()[key] for result in results])\n","        return distribution\n","    \n","    def save(self, filepath='results.json'):\n","        logging.info(f'Saving results in {filepath}')\n","        results = {idx: [result.dict() for result in results] for idx, results in self.results.items()}\n","        with open(filepath, 'w') as f:\n","            json.dump(results, f, indent=4)\n","\n","    def load(self, filepath):\n","        logging.info(f'Loading results from {filepath}')\n","        with open(filepath, 'r') as f:\n","            results = json.load(f)\n","        self.results = {int(idx): [InferenceResult(**result) for result in results] for idx, results in results.items()}\n","\n","    def __repr__(self):\n","        return str(self.results)\n","    \n","def get_minimum_most_frequent_value(counter_ret):\n","    max_count = counter_ret[0][1]\n","    candidates = []\n","    for value, count in counter_ret:\n","        if count == max_count:\n","            candidates.append(value)\n","        else:\n","            break\n","    return min(candidates), max_count\n","\n","class NoValidResults(Exception):\n","    pass\n","\n","assert get_minimum_most_frequent_value([(2, 1), (3, 1)]) == (2, 1)\n","assert get_minimum_most_frequent_value([(3, 1), (2, 1)]) == (2, 1)\n","assert get_minimum_most_frequent_value([(3, 2), (2, 1)]) == (3, 2)"]},{"cell_type":"markdown","metadata":{},"source":["### Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.524822Z","iopub.status.idle":"2024-05-20T07:55:29.525445Z","shell.execute_reply":"2024-05-20T07:55:29.525261Z","shell.execute_reply.started":"2024-05-20T07:55:29.525238Z"},"trusted":true},"outputs":[],"source":["def solve_problem_with_code_interpreter(prompt):\n","    text_generator.reset()\n","    clear_memory()\n","    code_runner = CodeRunner(CFG.max_coding_errors)\n","    decoded_output = prompt\n","    stop_word_cond = True\n","    generation_mode = 'text'\n","    while stop_word_cond and text_generator.are_generation_tokens_available():\n","        if decoded_output.endswith(\"Problem:\"):\n","            break\n","        is_code_block_finished = not decoded_output.endswith(\"```python\") and generation_mode == 'code'\n","        if is_code_block_finished:\n","            code_text = parse_last_python_code_block(decoded_output)\n","            code_output = code_runner.run_code(code_text)\n","            if code_runner.max_coding_errors_reached():\n","                break\n","            decoded_output = add_code_output_to_prompt(decoded_output, code_output)\n","\n","        if decoded_output.endswith(\"```python\"):\n","            decoded_output += '\\n'\n","            generation_mode = 'code'\n","        else:\n","            generation_mode = 'text'\n","\n","        decoded_output = text_generator(decoded_output, mode=generation_mode)\n","        stop_word_cond = any(decoded_output.endswith(stop_word) for stop_word in stop_words)\n","\n","    log_gpu_memory()\n","    if prompt.endswith(\"```python\"):\n","        decoded_output = decoded_output.replace(prompt, '```python')\n","        prompt = prompt[:-len(\"```python\")]\n","    else:\n","        decoded_output = decoded_output.replace(prompt, '')\n","    result = InferenceResult(\n","        prompt=prompt,\n","        response=decoded_output,\n","        output_tokens=text_generator.generated_tokens,\n","        coding_errors=code_runner.n_coding_errors,\n","        code_interpreter_calls=code_runner.code_interpreter_calls\n","    )\n","    if not text_generator.are_generation_tokens_available():\n","        # Solution was not achieved, it does not have sense to parse responses\n","        logging.warning(f'Max number of new tokens {CFG.max_new_tokens} was reached. Solution not found.')\n","        result.reached_max_tokens = True\n","    else:\n","        logging.info(f'Total generated tokens: {text_generator.generated_tokens}')\n","        if not code_runner.max_coding_errors_reached():\n","            result.boxed_answer = parse_boxed_answer(decoded_output)\n","            result.text_answer = parse_response_in_text(decoded_output)\n","            result.code_answer = parse_response_in_code(code_runner.successful_code_output)\n","    return result"]},{"cell_type":"markdown","metadata":{},"source":["### Show"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.526926Z","iopub.status.idle":"2024-05-20T07:55:29.527337Z","shell.execute_reply":"2024-05-20T07:55:29.527173Z","shell.execute_reply.started":"2024-05-20T07:55:29.527157Z"},"trusted":true},"outputs":[],"source":["def display_decoded_output(idx, text):\n","    display(Markdown('---'))\n","    display(Markdown(f'### Problem {idx}'))\n","    display(Markdown(text.replace('Assistant: ', 'Assistant: \\n')))\n","    display(Markdown('---'))"]},{"cell_type":"markdown","metadata":{},"source":["### Results analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.528562Z","iopub.status.idle":"2024-05-20T07:55:29.528976Z","shell.execute_reply":"2024-05-20T07:55:29.528812Z","shell.execute_reply.started":"2024-05-20T07:55:29.528780Z"},"trusted":true},"outputs":[],"source":["def show_inference_insights(results):\n","    keys = ['coding_errors', 'output_tokens', 'code_interpreter_calls']\n","    answers = ['boxed_answer', 'text_answer', 'code_answer']\n","    rows = []\n","    for idx in results.results:\n","        logging.info(f'Logging inference insights for problem {idx}')\n","        row = dict(n_runs=len(results.get_result_distribution(idx, keys[0])))\n","        for key in keys:\n","            values = results.get_result_distribution(idx, key)\n","            logging.info(f'{key} distribution: {values}')\n","            row[f'mean_{key}'] = round(np.mean(values), 1)\n","            row[f'median_{key}'] = round(np.median(values), 1)\n","        values = results.get_result_distribution(idx, 'reached_max_tokens')\n","        logging.info(f'reached_max_tokens distribution: {values}')\n","        row['unfinished_responses'] = np.sum(values)\n","        for answer in answers:\n","            values = results.get_result_distribution(idx, answer)\n","            logging.info(f'{answer} distribution: {values}')\n","            row[f'{answer}s'] = np.sum(values != None)\n","        rows.append(row)\n","        logging.info('')\n","    insights = pd.DataFrame(rows)\n","    summary = insights.sum()\n","    for column in insights.columns:\n","        if 'mean' in column or 'median' in column:\n","            summary[column] = round(summary[column] / len(insights), 1)\n","    insights.loc['all'] = summary\n","    for column in insights.columns[-5:]:\n","        insights[column] = (insights[column]/insights['n_runs']*100).round(1)\n","    return insights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.530627Z","iopub.status.idle":"2024-05-20T07:55:29.531021Z","shell.execute_reply":"2024-05-20T07:55:29.530856Z","shell.execute_reply.started":"2024-05-20T07:55:29.530841Z"},"trusted":true},"outputs":[],"source":["def get_accuracy_report(results, result_priority):\n","    report = df[['answer', 'ground_truth']].copy()\n","    report['answer'] = 0\n","    report['n_runs'] = 0\n","    report['correct_counts'] = 0\n","    report['highest_wrong_counts'] = 0\n","    report['wrong_counts'] = 0\n","    report['highest_correct_tokens'] = None\n","\n","    for idx in results.results:\n","        try:\n","            report.loc[idx, 'n_runs'] = get_n_runs(idx, results)\n","            values = np.array(results.get_valid_results(idx, result_priority))\n","            counter_ret = Counter(values).most_common()\n","            report.loc[idx, 'answer'] = get_minimum_most_frequent_value(counter_ret)[0]\n","            ground_truth = df.loc[idx, 'ground_truth']\n","            for pred, count in counter_ret:\n","                if pred == ground_truth:\n","                    report.loc[idx, 'correct_counts'] = count\n","                    break\n","            report.loc[idx, 'highest_wrong_counts'] = get_highest_wrong_count(counter_ret, ground_truth)\n","            report.loc[idx, 'wrong_counts'] = get_wrong_counts(counter_ret, ground_truth)\n","        except NoValidResults:\n","            report.loc[idx, 'answer'] = None\n","        if report.loc[idx, 'correct_counts'] > 0:\n","            report.loc[idx, 'highest_correct_tokens'] = get_highest_correct_tokens(idx, ground_truth, results)\n","    report['is_correct'] = (report['answer'] == report['ground_truth']).astype(int)\n","    report['pass'] = report['correct_counts'] > 0\n","    report.loc[report['answer'].isna(), 'is_correct'] = np.nan\n","    return add_summary_to_report(report)\n","\n","def add_summary_to_report(report):\n","    summary = report.sum()\n","    for key in report.columns[:2]:\n","        summary[key] = '-'\n","    summary['highest_correct_tokens'] = report['highest_correct_tokens'].max()\n","    report.loc['summary'] = summary\n","    return report\n","\n","def get_highest_wrong_count(counter_ret, ground_truth):\n","    for pred, count in counter_ret:\n","        if pred != ground_truth:\n","            return count\n","    return 0\n","\n","def get_wrong_counts(counter_ret, ground_truth):\n","    wrong_counts = 0\n","    for pred, count in counter_ret:\n","        if pred != ground_truth:\n","            wrong_counts += count\n","    return wrong_counts\n","\n","\n","def get_n_runs(idx, results):\n","    return len(results.results[idx])\n","\n","def get_highest_correct_tokens(idx, ground_truth, results):\n","    highest_correct_tokens = 0\n","    tokens = results.get_result_distribution(idx, 'output_tokens')\n","    for answer in CFG.result_priority:\n","        values = results.get_result_distribution(idx, answer)\n","        correct_answer_tokens = tokens[values == ground_truth]\n","        if len(correct_answer_tokens) > 0:\n","            max_tokens = max(correct_answer_tokens)\n","            highest_correct_tokens = max(highest_correct_tokens, max_tokens)\n","    return highest_correct_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:55:29.532427Z","iopub.status.idle":"2024-05-20T07:55:29.533154Z","shell.execute_reply":"2024-05-20T07:55:29.532948Z","shell.execute_reply.started":"2024-05-20T07:55:29.532925Z"},"trusted":true},"outputs":[],"source":["def analyze_MATH_results(result_priority):\n","    logging.info(f'Analyzing MATH results for {result_priority} priorities')\n","    accuracy_report = get_accuracy_report(results, result_priority)\n","    print_disaggregated_metrics(accuracy_report)\n","    accuracy_report = accuracy_report.loc[accuracy_report.index[:-1]]\n","    print_relevant_metrics(accuracy_report)\n","    for key in ['level', 'type']:\n","        accuracy_report[key] = df[key]\n","        plot_grouped_results(accuracy_report, key)\n","\n","\n","def print_relevant_metrics(accuracy_report):\n","    correct = accuracy_report['is_correct'].value_counts().get(1, 0)\n","    unanswered = accuracy_report['is_correct'].isna().sum()\n","    wrong = accuracy_report['is_correct'].value_counts().get(0, 0)\n","    total = correct + unanswered + wrong\n","    accuracy = correct/total\n","    print('\\tAggregated metrics majority vote')\n","    print(f'Correct: {correct}/{total} ({accuracy:.2f} ± {estimate_uncertainty(accuracy, total):.2f})')\n","    print(f'Unanswered: {unanswered}/{total} ({unanswered/total:.2f} ± {estimate_uncertainty(unanswered/total, total):.2f})')\n","    print(f'Wrong: {wrong}/{total} ({wrong/total:.2f} ± {estimate_uncertainty(wrong/total, total):.2f})')\n","    print('\\tAggregated metrics pass')\n","    correct = accuracy_report['pass'].sum()\n","    accuracy = correct/total\n","    print(f'Correct: {correct}/{total} ({accuracy:.2f} ± {estimate_uncertainty(accuracy, total):.2f})')\n","\n","\n","def estimate_uncertainty(proportion, n):\n","    return 1.96 * np.sqrt(proportion * (1 - proportion) / n)\n","\n","\n","def print_disaggregated_metrics(accuracy_report):\n","    correct = accuracy_report.loc['summary', 'correct_counts']\n","    wrong = accuracy_report.loc['summary', 'wrong_counts']\n","    total = accuracy_report.loc['summary', 'n_runs']\n","    unanswered = total - correct - wrong\n","    print('\\tDisaggregated metrics')\n","    print(f'Correct: {correct}/{total} ({correct/total:.2f} ± {estimate_uncertainty(correct/total, total):.2f})')\n","    print(f'Unanswered: {unanswered}/{total} ({unanswered/total:.2f} ± {estimate_uncertainty(unanswered/total, total):.2f})')\n","    print(f'Wrong: {wrong}/{total} ({wrong/total:.2f} ± {estimate_uncertainty(wrong/total, total):.2f})')\n","\n","\n","def plot_grouped_results(df, group):\n","    categories = sorted(df[group].unique().tolist())\n","    correct = []\n","    unanswered = []\n","    wrong = []\n","    for category in categories:\n","        correct.append(df[df[group] == category].is_correct.value_counts().get(1, 0))\n","        unanswered.append(df[df[group] == category].is_correct.isna().sum())\n","        wrong.append(df[df[group] == category].is_correct.value_counts().get(0, 0))\n","\n","    correct.append(np.sum(correct))\n","    unanswered.append(np.sum(unanswered))\n","    wrong.append(np.sum(wrong))\n","    categories.append('overall')\n","\n","    total = np.array(correct) + np.array(unanswered) + np.array(wrong)\n","    correct = np.array(correct)/total\n","    unanswered = np.array(unanswered)/total\n","    wrong = np.array(wrong)/total\n","    plt.bar(categories, correct, label='Correct', color='tab:green')\n","    plt.bar(categories, unanswered, bottom=correct, label='Unanswered', color='tab:orange')\n","    plt.bar(categories, wrong, bottom=np.array(correct)+np.array(unanswered), label='Wrong', color='tab:red')\n","    for idx, value in enumerate(categories):\n","        plt.text(value, correct[idx]/2, f'{correct[idx]*100:.0f}%', ha='center', va='center')\n","        plt.text(value, correct[idx] + unanswered[idx]/2, f'{unanswered[idx]*100:.0f}%', ha='center', va='center')\n","        plt.text(value, correct[idx] + unanswered[idx] + wrong[idx]/2, f'{wrong[idx]*100:.0f}%', ha='center', va='center')\n","    #plt.legend(loc=0)\n","    plt.ylim(0, 1)\n","    plt.grid(axis='y')\n","    plt.title(f'Results grouped by {group}')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["raise"]},{"cell_type":"markdown","metadata":{},"source":["## Merge results"]},{"cell_type":"markdown","metadata":{},"source":["### Merge results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def merge_results(results_filepaths, new_filepath):\n","    merged_results = dict()\n","    for results_idx, filepath in enumerate(results_filepaths):\n","        with open(filepath, 'r') as f:\n","            new_results = json.load(f)\n","        new_results = {int(idx)*len(results_filepaths) + results_idx: results for idx, results in new_results.items()}\n","        merged_results.update(new_results)\n","    with open(new_filepath, 'w') as f:\n","        json.dump(merged_results, f, indent=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merge_results(['/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-05-23_08:19:21_results.json',\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-05-23_08:48:16_results.json',],\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/02_public_notebook_prompts.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merge_results(['/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-05_03:09:43_results.json',\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-05_02:08:38_results.json',\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-05_09:47:32_results.json',\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-05_10:02:20_results.json',\n","               ],\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/05_multi_prompt.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merge_results(['/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-05_18:44:19_results.json',\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-06_01:24:28_results.json',\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-06_03:37:41_results.json',\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/2024-06-06_08:37:22_results.json',\n","               ],\n","               '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/06_multi_prompt_conf09.json')"]},{"cell_type":"markdown","metadata":{},"source":["### Concat results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def concat_results(results_filepaths, new_filepath):\n","    results_concat = dict()\n","    for filepath in results_filepaths:\n","        with open(filepath, 'r') as f:\n","            new_results = json.load(f)\n","        if not results_concat:\n","            results_concat = new_results\n","        else:\n","            for idx, results in new_results.items():\n","                results_concat[idx] += results\n","    # let's shuffle the results\n","    for idx in results_concat:\n","        np.random.shuffle(results_concat[idx])\n","    with open(new_filepath, 'w') as f:\n","        json.dump(results_concat, f, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filepaths = [\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-04_08:19:02_results.json', # v10 2 prompts\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-04_08:11:25_results.json', # v10 2 prompts\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_05:50:06_results.json', # v10 2 prompts\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-02_19:53:43_results.json', # v8\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-27_16:39:12_results.json', # v5 assistant\n","]\n","concat_results(filepaths, '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/03_2_prompts.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filepaths = sorted(glob.glob('/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/*.json'))\n","concat_results(filepaths, '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/04_all_evaluations.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["concat_results([\n","    '/mnt/hdd0/Kaggle/aimo/experiments/17_vllm/2024-06-12_08:46:54_results.json', # 200\n","    '/mnt/hdd0/Kaggle/aimo/experiments/17_vllm/2024-06-09_11:46:47_results.json', # 25\n","    '/mnt/hdd0/Kaggle/aimo/experiments/17_vllm/2024-06-10_04:47:21_results.json', # 100\n","    '/mnt/hdd0/Kaggle/aimo/experiments/17_vllm/2024-06-10_23:50:22_results.json', # 200 but with incorrect time limit\n","    ],\n","    '/mnt/hdd0/Kaggle/aimo/experiments/17_vllm/400_repetitions.json')"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Results reanalysis"]},{"cell_type":"markdown","metadata":{},"source":["### Define experiments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["experiment_to_results = {\n","    # 09_evaluate_MATH5\n","    'MATHCodeInstruct_10_4rep_2shot': '/mnt/hdd0/Kaggle/aimo/experiments/09_evaluate_MATH5/2024-05-15_08:35:58_results.json',\n","    '08_original_prompts': '/mnt/hdd0/Kaggle/aimo/experiments/09_evaluate_MATH5/2024-05-14_21:11:18_results.json',\n","    '11_original_code_prompt': '/mnt/hdd0/Kaggle/aimo/experiments/09_evaluate_MATH5/2024-05-15_11:53:30_results.json',\n","    '12_original_cot_prompt': '/mnt/hdd0/Kaggle/aimo/experiments/09_evaluate_MATH5/2024-05-15_11:33:15_results.json',\n","    # 10_temperature\n","    'AIMO_train_02_temperature_025': '/mnt/hdd0/Kaggle/aimo/experiments/10_temperature/2024-05-17_05:07:49_results.json',\n","    # 12_prompt_variations\n","    '01_original_code_with_python': '/mnt/hdd0/Kaggle/aimo/experiments/12_prompt_variations/2024-05-18_10:06:31_results.json',\n","    '02_original_cot_with_python': '/mnt/hdd0/Kaggle/aimo/experiments/12_prompt_variations/2024-05-18_10:02:56_results.json',\n","    '05_custom_prompt': '/mnt/hdd0/Kaggle/aimo/experiments/12_prompt_variations/2024-05-18_16:31:45_results.json',\n","    # 13_full_evaluation\n","    '01_3_python_prompts': '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/01_3_python_prompts.json',\n","    '02_public_notebook_prompts': '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/02_public_notebook_prompts.json',\n","    '03_2_prompts': '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/03_2_prompts.json',\n","    '04_all_evaluations': '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/04_all_evaluations.json',\n","    '05_multi_prompt': '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/05_multi_prompt.json',\n","    '06_multi_prompt_conf09': '/mnt/hdd0/Kaggle/aimo/experiments/13_full_evaluation/06_multi_prompt_conf09.json',\n","    'vll_400_repetitions': '/mnt/hdd0/Kaggle/aimo/experiments/17_vllm/400_repetitions.json',\n","}"]},{"cell_type":"markdown","metadata":{},"source":["### Reanalysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def reanalyze_results(experiment):\n","    global results\n","    results = Results()\n","    results.load(experiment_to_results[experiment])\n","    # reparse the text results with the new parsing functions\n","    for idx, inference_results in results.results.items():\n","        for inference_result in inference_results:\n","            inference_result.text_answer = parse_response_in_text(inference_result.response)\n","    for result_priority in [['code_answer'], ['text_answer'], ['code_answer', 'text_answer'], ['text_answer', 'code_answer']]:\n","        print(f'Analyzing results for {result_priority} priorities')\n","        accuracy_report = get_accuracy_report(results, result_priority)\n","        print_disaggregated_metrics(accuracy_report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reanalyze_results('03_2_prompts')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy_report_code = get_accuracy_report(results, ['code_answer'])\n","accuracy_report_text = get_accuracy_report(results, ['text_answer'])\n","(accuracy_report_code.is_correct - accuracy_report_text.is_correct).value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy_report_code.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["accuracy_report_code.loc['summary', 'highest_correct_tokens']"]},{"cell_type":"markdown","metadata":{},"source":["## Pairwise comparison"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def pairwise_comparison(experiment_1, experiment_2, result_priority=['code_answer', 'text_answer']):\n","    results_1 = Results()\n","    if not os.path.exists(experiment_1): experiment_1 = experiment_to_results[experiment_1]\n","    results_1.load(experiment_1)\n","    results_2 = Results()\n","    if not os.path.exists(experiment_2): experiment_2 = experiment_to_results[experiment_2]\n","    results_2.load(experiment_2)\n","    experiment_1_is_correct = get_accuracy_report(results_1, result_priority).is_correct.values[:-1]\n","    experiment_2_is_correct = get_accuracy_report(results_2, result_priority).is_correct.values[:-1]\n","    experiment_1_is_correct[np.isnan(experiment_1_is_correct)] = 0.5\n","    experiment_2_is_correct[np.isnan(experiment_2_is_correct)] = 0.5\n","    print_summarized_results('Experiment 1', experiment_1_is_correct)\n","    print_summarized_results('Experiment 2', experiment_2_is_correct)\n","    experiment_1_is_better = np.sum(experiment_1_is_correct - experiment_2_is_correct > 0)\n","    experiment_2_is_better = np.sum(experiment_2_is_correct - experiment_1_is_correct > 0)\n","    print(f'Experiment 1 is better in {experiment_1_is_better} problems, while experiment 2 is better in {experiment_2_is_better} problems')\n","    fast_pairwise_comparison_experiment(experiment_1_is_better, experiment_2_is_better)\n","\n","def print_summarized_results(prefix, is_correct):\n","    print(f'{prefix} Correct: {np.sum(is_correct==1)}, Unanswered: {np.sum(is_correct == 0.5)}, Wrong: {np.sum(is_correct==0)}')\n","\n","def run_pairwise_comparison_experiment(experiment_1_is_better, experiment_2_is_better, n_runs=1e5):\n","    distribution = [1]*experiment_1_is_better + [-1]*experiment_2_is_better\n","    diff_distribution = []\n","    for _ in range(int(n_runs)):\n","        resampled_distribution = np.random.choice(distribution, len(distribution), replace=True)\n","        diff_distribution.append(np.mean(resampled_distribution))\n","    plt.title('Experiment 1 - Experiment 2 bootstrapped difference distribution')\n","    plt.hist(diff_distribution, density=True, bins=20)\n","    plt.plot([0, 0], plt.ylim(), 'r')\n","    return diff_distribution\n","\n","def fast_pairwise_comparison_experiment(experiment_1_is_better, experiment_2_is_better):\n","    distribution = [1]*experiment_1_is_better + [-1]*experiment_2_is_better\n","    distribution_mean = np.mean(distribution)\n","    distribution_uncertainty = np.std(distribution)/np.sqrt(len(distribution))*1.96\n","    print(f'Experiment diff mean: {distribution_mean:.2f} ± {distribution_uncertainty:.2f}')\n","    if distribution_mean > distribution_uncertainty:\n","        print('Experiment 1 is better')\n","    elif distribution_mean < -distribution_uncertainty:\n","        print('Experiment 2 is better')\n","    else:\n","        print('No significant difference between experiments')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison(\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_05:50:06_results.json',\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_06:01:48_results.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison(\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_05:50:06_results.json',\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-27_04:01:40_results.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison(\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_05:50:06_results.json',\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-25_00:28:30_results.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison(\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_05:50:06_results.json',\n","    '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_06:01:48_results.json')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison('01_3_python_prompts', '02_public_notebook_prompts')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison('01_original_code_with_python', '11_original_code_prompt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison('01_3_python_prompts', '03_2_prompts')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison('05_multi_prompt', '03_2_prompts')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison('05_multi_prompt', '01_3_python_prompts')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pairwise_comparison('05_multi_prompt', '06_multi_prompt_conf09')"]},{"cell_type":"markdown","metadata":{},"source":["## Math results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['01_3_python_prompts'])\n","analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['03_2_prompts'])\n","analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['04_all_evaluations'])\n","analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['02_public_notebook_prompts'])\n","analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['05_multi_prompt'])\n","analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['06_multi_prompt_conf09'])\n","analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['vll_400_repetitions'])\n","analyze_MATH_results(['code_answer', 'text_answer'])"]},{"cell_type":"markdown","metadata":{},"source":["## Simulate effect of number of repetitions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def simulate_effect_of_number_of_repetitions(experiment, result_priority, max_repetitions=None):\n","    global results\n","    results = Results()\n","    if not os.path.exists(experiment): experiment = experiment_to_results[experiment]\n","    results.load(experiment)\n","    accuracy_report = get_accuracy_report(results, result_priority)\n","    max_repetitions = max_repetitions or accuracy_report.n_runs.values[:-1].max()\n","    n_repetitions_range = np.linspace(1, max_repetitions, 40).astype(int)\n","    n_repetitions_range = sorted(np.unique(n_repetitions_range))[::-1]\n","    #n_repetitions_range = np.arange(accuracy_report.n_runs.values[:-1].max(), 0, -1)\n","    correct, wrong, unanswered = [], [], []\n","    for n_repetitions in tqdm(n_repetitions_range):\n","        results.results = {idx: results.results[idx][:n_repetitions] for idx in results.results}\n","        accuracy_report = get_accuracy_report(results, result_priority)\n","        correct.append(np.mean(accuracy_report.is_correct == 1))\n","        wrong.append(np.mean(accuracy_report.is_correct == 0))\n","        unanswered.append(np.mean(accuracy_report.is_correct.isna()))\n","\n","    correct, wrong, unanswered = np.array(correct), np.array(wrong), np.array(unanswered)\n","    plt.fill_between(n_repetitions_range, 0, correct, label='Correct', color='tab:green', alpha=0.5)\n","    plt.fill_between(n_repetitions_range, correct, correct + unanswered, label='Unanswered', color='tab:orange', alpha=0.5)\n","    plt.fill_between(n_repetitions_range, correct + unanswered, correct + unanswered + wrong, label='Wrong', color='tab:red', alpha=0.5)\n","\n","    for x, y in zip(n_repetitions_range, correct):\n","        plt.text(x, y - 0.01, f'{y*100:.0f}%', ha='center', va='top')\n","\n","    plt.legend(loc='lower center')\n","    plt.grid()\n","    offset = 0.02\n","    plt.ylim(np.min(correct) - offset, np.max(correct + unanswered) + offset)\n","    plt.xlim(n_repetitions_range[-1], n_repetitions_range[0])\n","    plt.xlabel('Number of repetitions')\n","    plt.ylabel('Results')\n","    plt.title(f'Effect of the number of repetitions on {experiment} for {result_priority} priorities')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('vll_400_repetitions', result_priority=['code_answer', 'text_answer'], max_repetitions=400)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('/mnt/hdd0/Kaggle/aimo/experiments/17_vllm/2024-06-12_08:46:54_results.json', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('01_3_python_prompts', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('02_public_notebook_prompts', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('03_2_prompts', result_priority=['code_answer', 'text_answer'], max_repetitions=25)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('04_all_evaluations', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('05_multi_prompt', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_repetitions('06_multi_prompt_conf09', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"markdown","metadata":{},"source":["Maybe having more prompts is helpful?"]},{"cell_type":"markdown","metadata":{},"source":["## Simulate effect of the number of tokens"]},{"cell_type":"markdown","metadata":{},"source":["### Effect of the number of tokens"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def simulate_effect_of_number_of_tokens(experiment, result_priority):\n","    global results\n","    results = Results()\n","    results.load(experiment_to_results[experiment])\n","    accuracy_report = get_accuracy_report(results, result_priority)\n","    n_tokens_range = np.linspace(accuracy_report_code.loc['summary', 'highest_correct_tokens'], 128, 20)\n","    correct, wrong, unanswered = [], [], []\n","    for n_tokens in n_tokens_range:\n","        results.results = {idx: [result for result in inference_results if result.output_tokens < n_tokens] for idx, inference_results in results.results.items()}\n","        accuracy_report = get_accuracy_report(results, result_priority)\n","        correct.append(np.mean(accuracy_report.is_correct == 1))\n","        wrong.append(np.mean(accuracy_report.is_correct == 0))\n","        unanswered.append(np.mean(accuracy_report.is_correct.isna()))\n","\n","    correct, wrong, unanswered = np.array(correct), np.array(wrong), np.array(unanswered)\n","    plt.fill_between(n_tokens_range, 0, correct, label='Correct', color='tab:green', alpha=0.5)\n","    plt.fill_between(n_tokens_range, correct, correct + unanswered, label='Unanswered', color='tab:orange', alpha=0.5)\n","    plt.fill_between(n_tokens_range, correct + unanswered, correct + unanswered + wrong, label='Wrong', color='tab:red', alpha=0.5)\n","\n","    for x, y in zip(n_tokens_range, correct):\n","        plt.text(x, y - 0.01, f'{y*100:.0f}%', ha='center', va='top')\n","\n","    plt.legend(loc='lower center')\n","    plt.grid()\n","    offset = 0.02\n","    plt.ylim(np.min(correct) - offset, np.max(correct + unanswered) + offset)\n","    plt.xlim(n_tokens_range[-1], n_tokens_range[0])\n","    plt.xlabel('Number of output tokens')\n","    plt.ylabel('Results')\n","    plt.title(f'Effect of the number of output tokens on {experiment} for {result_priority} priorities')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_tokens('01_3_python_prompts', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["simulate_effect_of_number_of_tokens('02_public_notebook_prompts', result_priority=['code_answer', 'text_answer'])"]},{"cell_type":"markdown","metadata":{},"source":["### Token distribution"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_output_tokens_distribution(experiment, result_priority):\n","    global results\n","    results = Results()\n","    results.load(experiment_to_results[experiment])\n","    correct_answer_tokens, wrong_answer_tokens = [], []\n","    for problem_idx in results.results:\n","        ground_truth = df.loc[problem_idx, 'ground_truth']\n","        tokens = results.get_result_distribution(problem_idx, 'output_tokens')\n","        values = [None for _ in range(len(tokens))]\n","        for answer in result_priority:\n","            new_values = results.get_result_distribution(problem_idx, answer)\n","            for idx, value in enumerate(new_values):\n","                if value is not None:\n","                    values[idx] = value\n","        values = np.array(values)\n","        correct_answer_tokens.extend(tokens[values == ground_truth].tolist())\n","        wrong_answer_tokens.extend(tokens[values != ground_truth].tolist())\n","\n","    bins = np.linspace(0, np.max(wrong_answer_tokens), 20)\n","    plt.hist(correct_answer_tokens, alpha=0.5, label='Correct', bins=bins, density=True)\n","    plt.hist(wrong_answer_tokens, alpha=0.5, label='Wrong', bins=bins, density=True)\n","    plt.legend(loc=0)\n","    plt.title(f'Output token distribution for {experiment} for {result_priority} priorities')\n","\n","    return correct_answer_tokens + wrong_answer_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output_tokens = plot_output_tokens_distribution('01_3_python_prompts', result_priority=['code_answer', 'text_answer'])\n","np.sum(output_tokens), np.sum(np.clip(output_tokens, 0, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["25*44/32"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output_tokens = plot_output_tokens_distribution('02_public_notebook_prompts', result_priority=['code_answer', 'text_answer'])\n","np.sum(output_tokens), np.sum(np.clip(output_tokens, 0, 512))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["25*52/37"]},{"cell_type":"markdown","metadata":{},"source":["We might increase the repetitions from 25 to 35 if reducing the output tokens from 1024 to 512"]},{"cell_type":"markdown","metadata":{},"source":["## Results analysis\n"]},{"cell_type":"markdown","metadata":{},"source":["- Distribution of correct answers per problem\n","- Distribution of the number of runs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['04_all_evaluations'])\n","accuracy_report = get_accuracy_report(results, ['code_answer', 'text_answer'])\n","accuracy_report = accuracy_report.loc[accuracy_report.index[:-1]]\n","accuracy_report.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bins = np.arange(-.5, 26, 1)\n","plt.hist(accuracy_report['n_runs'], bins=bins)\n","plt.title('Distribution of the number of runs per problem');"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bins = np.arange(-0.5, 20, 1)\n","plt.hist(accuracy_report['correct_counts'], bins=bins)\n","plt.title('Distribution of the number of correct counts per problem');"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(accuracy_report['correct_counts'] == 0).mean()"]},{"cell_type":"markdown","metadata":{},"source":["## What if I remove answers with more than one code execution?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = Results()\n","results.load(experiment_to_results['03_2_prompts'])\n","analyze_MATH_results(['code_answer'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results.results = {idx: [inference_result for inference_result in inference_results if inference_result.code_interpreter_calls == 1] for idx, inference_results in results.results.items()}\n","analyze_MATH_results(['code_answer'])"]},{"cell_type":"markdown","metadata":{},"source":["The accuracy decreases from 57% to 54% when only allowing one code execution, however the estimation is not totally fair because the inference would have been different (maybe more runs)"]},{"cell_type":"markdown","metadata":{},"source":["## Can I find a better combination of prompts?"]},{"cell_type":"markdown","metadata":{},"source":["Let's do a random search to select 5 out of all evaluations and maximize the accuracy on the MATH dataset.\n","\n","The baseline is 332 correct answers."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filepaths = sorted(glob.glob('/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/*.json'))\n","n_runs = 6000\n","n_samples = 7\n","search_results = []\n","for _ in tqdm(range(n_runs)):\n","    sample_filepaths = sorted(np.random.choice(filepaths, n_samples, replace=False))\n","    try:\n","        concat_results(sample_filepaths, 'delete.json')\n","    except KeyError:\n","        continue\n","    results = Results()\n","    results.load('delete.json')\n","    accuracy_report = get_accuracy_report(results, ['code_answer', 'text_answer'])\n","    correct = accuracy_report.is_correct.value_counts().get(1, 0)\n","    print(correct)\n","    search_results.append([correct, sample_filepaths])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.hist([result[0] for result in search_results])"]},{"cell_type":"markdown","metadata":{},"source":["```python\n","\n","[361,\n","  ['/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-27_04:01:40_results.json', # 09 AIMO train 2 shots\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-28_05:18:13_results.json', # custom prompt v7\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-30_22:22:00_results.json',\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-31_09:27:26_results.json',\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-01_04:42:58_results.json', # AIMO 2 shots assistant t09\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-01_04:49:02_results.json', # AIMO 2 shots assistant t20\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-02_05:28:41_results.json'  # 20 AIMO 2 shots assistant \n","   ]\n","],\n","\n","[[360,\n","  ['/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-29_05:42:08_results.json', # 16 AIMO 2 shots assistant\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-30_05:40:33_results.json', # 19 AIMO 2 shots assistant t02\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-31_03:51:32_results.json', # 20 AIMO 2 shots assistant t07\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-31_09:27:26_results.json', \n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-02_05:28:41_results.json', # 20 AIMO 2 shots assistant \n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-03_05:50:06_results.json', # 2 assistant\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-04_08:11:25_results.json' # 2 assistant\n","]],\n","\n","\n","[\n","    357,\n","'/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-01_04:42:58_results.json', # AIMO 2 shots assistant t09\n","'/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-04_08:11:25_results.json', # 2 assistant\n","'/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-01_04:49:02_results.json', # AIMO 2 shots assistant t20\n","'/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-26_02:53:20_results.json', # custom prompt v3 list\n","'/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-25_00:28:30_results.json', # 01 public notebook prompts\n","]\n","\n","[[356,\n","  ['/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-26_02:53:20_results.json', # custom prompt v3 list\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-05-27_04:01:40_results.json', # 09 AIMO train 2 shots\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-02_05:21:38_results.json', # 20 AIMO 2 shots assistant t09 top_p 0.5\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-02_05:28:41_results.json', # 20 AIMO 2 shots assistant t07 top_p 0.5\n","   '/mnt/hdd0/Kaggle/aimo/experiments/15_prompt_engineering/2024-06-04_08:11:25_results.json' # 2 assistant\n","]],\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["357/580"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sorted(search_results, key=lambda x: x[0], reverse=True)[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sorted(search_results, key=lambda x: x[0], reverse=True)[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sorted(search_results, key=lambda x: x[0], reverse=True)[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["357/580"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sorted(search_results, key=lambda x: x[0], reverse=True)[:5]"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8365361,"sourceId":73231,"sourceType":"competition"},{"datasetId":4281572,"sourceId":7369493,"sourceType":"datasetVersion"},{"datasetId":4720595,"sourceId":8012825,"sourceType":"datasetVersion"},{"datasetId":4728129,"sourceId":8023365,"sourceType":"datasetVersion"},{"datasetId":4748944,"sourceId":8052555,"sourceType":"datasetVersion"},{"datasetId":4950771,"sourceId":8424919,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":724.728315,"end_time":"2024-02-29T09:37:08.760349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-29T09:25:04.032034","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"21267b653022419eb6fc3f47aa4db8ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926e7ccdad6440be85c76931860b744c","placeholder":"​","style":"IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67","value":"Loading checkpoint shards: 100%"}},"2144e851698b4707ad1c7fc29fe21b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3963993becfa487c9ff725f211915e67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065","placeholder":"​","style":"IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca","value":" 19/19 [10:48&lt;00:00, 33.24s/it]"}},"5882b6e860be4a0db012a64fc0704a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed","IPY_MODEL_d91eb83d016a4381828192a98f798f9b","IPY_MODEL_3963993becfa487c9ff725f211915e67"],"layout":"IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"}},"6a892a5561f742bb9db9f13859c18e90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926e7ccdad6440be85c76931860b744c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91eb83d016a4381828192a98f798f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0693b32889c42b18b9a3844e045d048","value":19}},"e0693b32889c42b18b9a3844e045d048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7a725e1b0cc4ad78a62beab5f663065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb32baaed7145d8a8024b615ef242ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feef8334edb24f6da22e8bb1d8d80c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":4}
