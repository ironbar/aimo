{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5\n",
    "- https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "Is teh best ranked model with an acceptable size and open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires sentence_transformers>=2.7.0\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sentences = ['That is a happy person', 'That is a very happy person']\n",
    "\n",
    "model = SentenceTransformer('Alibaba-NLP/gte-large-en-v1.5',\n",
    "                            trust_remote_code=True,\n",
    "                            device='cpu')\n",
    "embeddings = model.encode(sentences)\n",
    "print(cos_sim(embeddings[0], embeddings[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load problems data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/mnt/hdd0/Kaggle/aimo/external_data/filtered_MATH_test_5.csv')\n",
    "test.sort_values('type', inplace=True)\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/mnt/hdd0/Kaggle/aimo/external_data/filtered_MATH_train.csv')\n",
    "train = train[train.level == 'Level 5']\n",
    "train.sort_values('type', inplace=True)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_problems = test.problem.values.copy()\n",
    "train_problems = train.problem.values.copy()\n",
    "len(test_problems), len(train_problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = model.encode(train_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = model.encode(test_problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is computing around 3 embeddings per second, fast enough for our application (only 50 embeddings need to be computed at test time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cos_sim(test_embeddings, train_embeddings).numpy()\n",
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(similarity);\n",
    "plt.xlabel('Train')\n",
    "plt.ylabel('Test')\n",
    "plt.title('Cosine-Similarity between test and train problems');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some diagonal structure, that is intended because the problems were sorted by type of problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for the n most similar problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_n_most_similar_problems(idx, n=5):\n",
    "    most_similar = np.argsort(similarity[idx])[::-1][:n]\n",
    "\n",
    "    display_markdown(f\"### Test Problem {idx}. {test['type'].values[idx]}\\n\\n {test_problems[idx]}\")\n",
    "    for i, j in enumerate(most_similar):\n",
    "        display_markdown(f\"### Train Problem {j}. {train['type'].values[j]}, Similarity: {similarity[idx, j]:.2f}\")\n",
    "        display_markdown(f\"{train_problems[j]}\")\n",
    "\n",
    "def display_markdown(text):\n",
    "    display(Markdown(uniform_latex_format(text)))\n",
    "    # display(Markdown(text))\n",
    "    # print(text)\n",
    "    # display(Markdown(uniform_latex_format(text)))\n",
    "    #print(uniform_latex_format(text))\n",
    "\n",
    "def uniform_latex_format(text):\n",
    "    text = text.replace('\\\\[', ' $ ').replace('\\\\]', ' $ ')\n",
    "    text = text.replace('\\\\(', '$').replace('\\\\)', '$')\n",
    "    text = text.replace('\\\\begin{align*}', ' $$ ').replace('\\\\end{align*}', ' $$ ')\n",
    "    return text\n",
    "\n",
    "\n",
    "show_n_most_similar_problems(50, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be working well enough, maybe we need something more advanced, but we should measure how good this is on evaluation compared to random using the problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.problem.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prometeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
